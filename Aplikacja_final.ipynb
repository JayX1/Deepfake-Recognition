{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc2ccd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import zipfile\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import numpy as np\n",
    "\n",
    "#Funkcja do rozpakowania plików zip do nowej ścieżki\n",
    "def unzip_file(zip_path: Path, extract_path: Path) -> Path:\n",
    "    extract_path.mkdir(parents=True, exist_ok=True)\n",
    "    # Jeśli katalog nie jest pusty, zakładamy, że już rozpakowane\n",
    "    if any(extract_path.iterdir()):\n",
    "        return extract_path\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "        z.extractall(extract_path)\n",
    "    return extract_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b993807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/datasets/ayushmandatta1/deepdetect-2025/data\n",
    "# dataset_a-> ddata-> {test,train}-> {real,fake} \n",
    "#--------------------------------------------------------\n",
    "#https://www.kaggle.com/datasets/manjilkarki/deepfake-and-real-images\n",
    "# dataset_b-> {test,train,validation}->{real,fake}\n",
    "#--------------------------------------------------------\n",
    "#https://www.kaggle.com/datasets/saurabhbagchi/deepfake-image-detection\n",
    "#dataset_c-> {}\n",
    "#https://www.kaggle.com/datasets/peilwang/deepfake\n",
    "#dataset_d\n",
    "#_____________________________________________________________________\n",
    "\n",
    "app_dir = Path(\"C:/Users/blend/inzynierka\")\n",
    "#Ścieżki do danych w .zip\n",
    "zip_path_A = app_dir/\"Dane/Dataset_A.zip\"\n",
    "zip_path_B = app_dir/\"Dane/Dataset_B.zip\"\n",
    "zip_path_C = app_dir/\"Dane/Dataset_C.zip\"\n",
    "zip_path_D = app_dir/\"Dane/Dataset_D.zip\"\n",
    "\n",
    "#Nowe ścieżki do rozpakowania zip\n",
    "extract_path_A = app_dir/\"Dane/Dataset_A_extract\"\n",
    "extract_path_B = app_dir/\"Dane/Dataset_B_extract\"\n",
    "extract_path_C = app_dir/\"Dane/Dataset_C_extract\"\n",
    "extract_path_D = app_dir/\"Dane/Dataset_D_extract\"\n",
    "\n",
    "#Rozpakowanie\n",
    "unzip_file(zip_path_A,extract_path_A)\n",
    "unzip_file(zip_path_B,extract_path_B)\n",
    "unzip_file(zip_path_C,extract_path_C)\n",
    "unzip_file(zip_path_D,extract_path_D)\n",
    "\n",
    "train_path_A = extract_path_A / \"ddata\" / \"train\"\n",
    "test_path_A = extract_path_A / \"ddata\" / \"test\"\n",
    "\n",
    "train_path_B = extract_path_B /\"Dataset\"/ \"Train\"\n",
    "test_path_B = extract_path_B / \"Dataset\"/\"Test\"\n",
    "\n",
    "train_path_C = extract_path_C /\"train\" / \"train\"\n",
    "test_path_C = extract_path_C /\"test\" / \"test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a988443f-63f7-419f-8e8f-d934459f46e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv, shutil\n",
    "\n",
    "def convert_D(extract_path_D: Path):\n",
    "    phase1 = next(extract_path_D.rglob(\"phase1\"))\n",
    "\n",
    "    src = {\n",
    "        \"train\": (phase1 / \"trainset\", phase1 / \"trainset_label.txt\"),\n",
    "        \"test\":  (phase1 / \"valset\",   phase1 / \"valset_label.txt\"),\n",
    "    }\n",
    "\n",
    "    out_root = extract_path_D / \"Dataset_D\"\n",
    "    label2cls = {0: \"real\", 1: \"fake\"}  # flip if needed\n",
    "\n",
    "    def read_labels(p: Path):\n",
    "        items = []\n",
    "        with open(p, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "            for row in csv.reader(f):\n",
    "                if len(row) < 2:\n",
    "                    continue\n",
    "                img, lab = row[0].strip(), row[1].strip()\n",
    "                if not lab.isdigit():   # skip header\n",
    "                    continue\n",
    "                items.append((img, int(lab)))\n",
    "        return items\n",
    "\n",
    "    def find_img(folder: Path, name: str) -> Path:\n",
    "        p = folder / name\n",
    "        if p.exists():\n",
    "            return p\n",
    "        hits = list(folder.rglob(Path(name).name))  # fallback if nested\n",
    "        if hits:\n",
    "            return hits[0]\n",
    "        raise FileNotFoundError(name)\n",
    "\n",
    "    for split, (img_dir, lab_file) in src.items():\n",
    "        for img_name, lab in read_labels(lab_file):\n",
    "            cls = label2cls[lab]\n",
    "            dst = out_root / split / cls / Path(img_name).name\n",
    "            dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "            if dst.exists():\n",
    "                continue\n",
    "            try:\n",
    "                shutil.copy2(find_img(img_dir, img_name), dst)\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "    return out_root / \"train\", out_root / \"test\"\n",
    "\n",
    "\n",
    "train_path_D, test_path_D = convert_D(extract_path_D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca81f927-34bb-4650-bd2b-73410bb3d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_C = extract_path_C /\"train\" / \"train\"\n",
    "test_path_C = extract_path_C /\"test\" / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4fee796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad A train/test: 2 0\n",
      "Bad B train/test: 0 0\n",
      "Bad C train/test: 0 0\n",
      "Bad D train/test: 0 0\n"
     ]
    }
   ],
   "source": [
    "#Akceptowane formaty plików\n",
    "EXTS = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"}\n",
    "LABEL_MAP = {\"fake\": 0.0, \"real\": 1.0}\n",
    "\n",
    "#Sprawdzanie czy tensorflow potrafi poprawnie odczytać zdjęcie\n",
    "def tf_ok(p: Path) -> bool:\n",
    "    try:\n",
    "        b = tf.io.read_file(str(p))\n",
    "        _ = tf.io.decode_image(b, channels=3, expand_animations=False)\n",
    "        return True\n",
    "    except (tf.errors.InvalidArgumentError, tf.errors.DataLossError, tf.errors.NotFoundError):\n",
    "        return False\n",
    "\n",
    "#przetworzenie plików ze ścieżek w listy poprawnych zdjęć i ich etykiet oraz odpadów\n",
    "def collect_good(root: Path, fake_dir=\"fake\", real_dir=\"real\"):\n",
    "    fake_folder = root / fake_dir\n",
    "    real_folder = root / real_dir\n",
    "    if not fake_folder.exists() or not real_folder.exists():\n",
    "        raise FileNotFoundError(f\"Expected {fake_folder} and {real_folder}\")\n",
    "\n",
    "    paths, labels, bad = [], [], 0\n",
    "    for folder, lab in [(fake_folder, LABEL_MAP[\"fake\"]), (real_folder, LABEL_MAP[\"real\"])]:\n",
    "        for p in folder.rglob(\"*\"):\n",
    "            if p.is_file() and p.suffix.lower() in EXTS:\n",
    "                if tf_ok(p):\n",
    "                    paths.append(str(p))\n",
    "                    labels.append(lab)\n",
    "                else:\n",
    "                    bad += 1\n",
    "    return paths, labels, bad\n",
    "\n",
    "\n",
    "#Listy train/test i odpady\n",
    "train_dir_A, train_labels_A, bad_train_A = collect_good(train_path_A)\n",
    "test_dir_A,  test_labels_A,  bad_test_A  = collect_good(test_path_A)\n",
    "\n",
    "train_dir_B, train_labels_B, bad_train_B = collect_good(train_path_B, \"Fake\", \"Real\")\n",
    "test_dir_B,  test_labels_B,  bad_test_B  = collect_good(test_path_B, \"Fake\", \"Real\")\n",
    "\n",
    "train_dir_C, train_labels_C, bad_train_C = collect_good(train_path_C)\n",
    "test_dir_C,  test_labels_C,  bad_test_C  = collect_good(test_path_C)\n",
    "\n",
    "train_dir_D, train_labels_D, bad_train_D = collect_good(train_path_D)\n",
    "test_dir_D,  test_labels_D,  bad_test_D  = collect_good(test_path_D)\n",
    "\n",
    "#Raport ile odpadów\n",
    "print(\"Bad A train/test:\", bad_train_A, bad_test_A)\n",
    "print(\"Bad B train/test:\", bad_train_B, bad_test_B)\n",
    "print(\"Bad C train/test:\", bad_train_C, bad_test_C)\n",
    "print(\"Bad D train/test:\", bad_train_D, bad_test_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aee97cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deklarowanie parametrów\n",
    "IMG_SIZE=(256,256);\n",
    "BATCH=32;\n",
    "SEED=42;\n",
    "VAL_SPLIT=0.2\n",
    "AUTOTUNE=tf.data.AUTOTUNE #Wbudowana optymalizacja CPU/GPU dla tensorflow\n",
    "\n",
    "#Tworzenie tensorflow dataset do szybkiego czytania obrazów \n",
    "def make_ds(paths, labels, training: bool):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    #Tasowanie danych dla treningu\n",
    "    if training:\n",
    "        ds = ds.shuffle(min(len(paths), 20000), seed=SEED, reshuffle_each_iteration=True)\n",
    "\n",
    "        \n",
    "    def load(path, label):\n",
    "        #Dekoduje obraz ze ścieżki w RGB i zamraża GIF\n",
    "        img = tf.io.decode_image(tf.io.read_file(path), channels=3, expand_animations=False)\n",
    "        #Resize do 256x256\n",
    "        img = tf.image.resize(img, IMG_SIZE)\n",
    "        #konwersja na float na potrzeby uczenia mdelu\n",
    "        img = tf.cast(img, tf.float32)  # keep 0..255 for EfficientNet preprocess_input\n",
    "        #Reshpe dla Dense(1, sigmoid) i loss binary_crossentropy\n",
    "        return img, tf.reshape(label, (1,))\n",
    "    #Wielowątkowe ładowanie dla batcha po 32 obrazy\n",
    "    return ds.map(load, num_parallel_calls=AUTOTUNE).batch(BATCH).prefetch(AUTOTUNE)\n",
    "\n",
    "#Split na dane treningowe i walidacyjne\n",
    "def split_train_val(paths, labels):\n",
    "    n = len(paths)\n",
    "    idx = tf.random.shuffle(tf.range(n), seed=SEED).numpy()\n",
    "    cut = int(n*(1-VAL_SPLIT))\n",
    "    tr, va = idx[:cut], idx[cut:]\n",
    "    tr_paths  = [paths[i] for i in tr]; tr_labels = [labels[i] for i in tr]\n",
    "    va_paths  = [paths[i] for i in va]; va_labels = [labels[i] for i in va]\n",
    "    return tr_paths, tr_labels, va_paths, va_labels\n",
    "\n",
    "#Tworzenie folda na potrzeby LODO\n",
    "def build_fold(train_pairs, test_pair):\n",
    "    # train_pairs: list of (train_paths, train_labels) for 2 datasets\n",
    "    # test_pair:   (test_paths, test_labels) for held-out dataset\n",
    "    train_paths = sum([p for p,_ in train_pairs], [])\n",
    "    train_labels= sum([y for _,y in train_pairs], [])\n",
    "\n",
    "    trp, try_, vap, vay = split_train_val(train_paths, train_labels)\n",
    "\n",
    "    train_ds = make_ds(trp, try_, True)\n",
    "    val_ds   = make_ds(vap, vay, False)\n",
    "\n",
    "    test_paths, test_labels = test_pair\n",
    "    test_ds  = make_ds(test_paths, test_labels, False)\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8760c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "def probs_and_labels(ds, model):\n",
    "    y_true = np.concatenate([y.numpy().reshape(-1) for _, y in ds], axis=0).astype(int)\n",
    "    y_prob = model.predict(ds, verbose=0).reshape(-1)\n",
    "    return y_true, y_prob\n",
    "\n",
    "def best_threshold_on_val(model, val_ds):\n",
    "    yv, pv = probs_and_labels(val_ds, model)\n",
    "    ths = np.linspace(0.05, 0.95, 91)\n",
    "    best = {\"t\": 0.5, \"f1\": -1}\n",
    "    for t in ths:\n",
    "        pred = (pv >= t).astype(int)\n",
    "        f1 = f1_score(yv, pred)\n",
    "        if f1 > best[\"f1\"]:\n",
    "            best = {\n",
    "                \"t\": float(t),\n",
    "                \"f1\": float(f1),\n",
    "                \"precision\": float(precision_score(yv, pred)),\n",
    "                \"recall\": float(recall_score(yv, pred)),\n",
    "                \"bal_acc\": float(balanced_accuracy_score(yv, pred)),\n",
    "            }\n",
    "    return best\n",
    "\n",
    "def run_fold(train_ds, val_ds, test_ds):\n",
    "    base = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(256,256,3))\n",
    "    base.trainable = False\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input((256,256,3)),\n",
    "        tf.keras.layers.Lambda(preprocess_input),\n",
    "        base,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    def compile_model(lr):\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(lr),\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[tf.keras.metrics.AUC(name=\"auc\"),\n",
    "                     tf.keras.metrics.BinaryAccuracy(name=\"acc\", threshold=0.5)]\n",
    "        )\n",
    "\n",
    "    # stage 1\n",
    "    compile_model(1e-3)\n",
    "    model.fit(train_ds, validation_data=val_ds, epochs=3,\n",
    "              callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=1, restore_best_weights=True)])\n",
    "\n",
    "    # stage 2 fine-tune\n",
    "    base.trainable = True\n",
    "    for layer in base.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    compile_model(1e-5)\n",
    "    model.fit(train_ds, validation_data=val_ds, epochs=3,\n",
    "              callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=1, restore_best_weights=True)])\n",
    "\n",
    "    # threshold on val\n",
    "    th = best_threshold_on_val(model, val_ds)\n",
    "\n",
    "    # test metrics\n",
    "    yt, pt = probs_and_labels(test_ds, model)\n",
    "    pred = (pt >= th[\"t\"]).astype(int)\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"auc\": float(roc_auc_score(yt, pt)),\n",
    "        \"bal_acc\": float(balanced_accuracy_score(yt, pred)),\n",
    "        \"f1\": float(f1_score(yt, pred)),\n",
    "        \"precision\": float(precision_score(yt, pred)),\n",
    "        \"recall\": float(recall_score(yt, pred)),\n",
    "        \"thr\": th\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e48187cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# def get_y_true(ds):\n",
    "#     return np.concatenate([y.numpy().reshape(-1) for _, y in ds]).astype(int)\n",
    "\n",
    "# def get_y_prob(model, ds):\n",
    "#     return model.predict(ds, verbose=0).reshape(-1)\n",
    "\n",
    "# # Dataset units\n",
    "# A_train = (train_dir_A, train_labels_A)\n",
    "# A_test  = (test_dir_A,  test_labels_A)\n",
    "# B_train = (train_dir_B, train_labels_B)\n",
    "# B_test  = (test_dir_B,  test_labels_B)\n",
    "# C_train = (train_dir_C, train_labels_C)\n",
    "# C_test  = (test_dir_C,  test_labels_C)\n",
    "\n",
    "# folds = [\n",
    "#     ([A_train, B_train], C_test, \"AB->C\"),\n",
    "#     ([A_train, C_train], B_test, \"AC->B\"),\n",
    "#     ([B_train, C_train], A_test, \"BC->A\"),\n",
    "# ]\n",
    "\n",
    "# results = []\n",
    "# for train_pairs, test_pair, name in folds:\n",
    "#     train_ds, val_ds, test_ds = build_fold(train_pairs, test_pair)\n",
    "\n",
    "#     r = run_fold(train_ds, val_ds, test_ds)   # <- r must include r[\"model\"] and r[\"thr\"][\"t\"] (or pick 0.5)\n",
    "#     r[\"fold\"] = name\n",
    "\n",
    "#     model = r[\"model\"]\n",
    "#     thr = r[\"thr\"][\"t\"] if isinstance(r.get(\"thr\"), dict) and \"t\" in r[\"thr\"] else 0.5\n",
    "\n",
    "#     y_true = get_y_true(test_ds)\n",
    "#     y_prob = get_y_prob(model, test_ds)\n",
    "#     y_pred = (y_prob >= thr).astype(int)\n",
    "\n",
    "#     cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "#     r[\"cm\"] = cm\n",
    "\n",
    "#     results.append(r)\n",
    "\n",
    "#     print(\"\\n\", name, {k: r[k] for k in [\"auc\",\"bal_acc\",\"f1\",\"precision\",\"recall\"] if k in r})\n",
    "#     print(\"threshold:\", thr)\n",
    "#     print(\"confusion matrix [[TN FP],[FN TP]]:\\n\", cm)\n",
    "\n",
    "# # average\n",
    "# for k in [\"auc\",\"bal_acc\",\"f1\",\"precision\",\"recall\"]:\n",
    "#     vals = [r[k] for r in results]\n",
    "#     print(k, \"mean±std =\", float(np.mean(vals)), \"±\", float(np.std(vals)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a128209",
   "metadata": {},
   "source": [
    "Epoch 1/3\n",
    "5761/5761 ━━━━━━━━━━━━━━━━━━━━ 3270s 566ms/step - acc: 0.7094 - auc: 0.7826 - loss: 0.5599 - val_acc: 0.7539 - val_auc: 0.8382 - val_loss: 0.5051\n",
    "Epoch 2/3\n",
    "5761/5761 ━━━━━━━━━━━━━━━━━━━━ 3197s 555ms/step - acc: 0.7229 - auc: 0.7982 - loss: 0.5442 - val_acc: 0.7608 - val_auc: 0.8423 - val_loss: 0.4973\n",
    "Epoch 3/3\n",
    "5761/5761 ━━━━━━━━━━━━━━━━━━━━ 3211s 557ms/step - acc: 0.7232 - auc: 0.7995 - loss: 0.5429 - val_acc: 0.7559 - val_auc: 0.8422 - val_loss: 0.4994\n",
    "Epoch 1/3\n",
    "5761/5761 ━━━━━━━━━━━━━━━━━━━━ 3821s 662ms/step - acc: 0.7797 - auc: 0.8646 - loss: 0.4569 - val_acc: 0.8823 - val_auc: 0.9525 - val_loss: 0.2865\n",
    "Epoch 2/3\n",
    "5761/5761 ━━━━━━━━━━━━━━━━━━━━ 3740s 649ms/step - acc: 0.8743 - auc: 0.9473 - loss: 0.2941 - val_acc: 0.9172 - val_auc: 0.9755 - val_loss: 0.2057\n",
    "Epoch 3/3\n",
    "5761/5761 ━━━━━━━━━━━━━━━━━━━━ 3767s 654ms/step - acc: 0.9037 - auc: 0.9670 - loss: 0.2331 - val_acc: 0.9338 - val_auc: 0.9833 - val_loss: 0.1685\n",
    "\n",
    " AB->C {'auc': 0.4099789670483758, 'bal_acc': 0.5068357092778687, 'f1': 0.3614457831325301, 'precision': 0.2229299363057325, 'recall': 0.9545454545454546}\n",
    "threshold: 0.43999999999999995\n",
    "confusion matrix [[TN FP],[FN TP]]:\n",
    " [[ 23 366]\n",
    " [  5 105]]\n",
    "Epoch 1/3\n",
    "2273/2273 ━━━━━━━━━━━━━━━━━━━━ 1279s 560ms/step - acc: 0.7757 - auc: 0.8587 - loss: 0.4707 - val_acc: 0.8243 - val_auc: 0.9117 - val_loss: 0.4005\n",
    "Epoch 2/3\n",
    "2273/2273 ━━━━━━━━━━━━━━━━━━━━ 1274s 560ms/step - acc: 0.8066 - auc: 0.8870 - loss: 0.4234 - val_acc: 0.8284 - val_auc: 0.9244 - val_loss: 0.3840\n",
    "Epoch 3/3\n",
    "2273/2273 ━━━━━━━━━━━━━━━━━━━━ 1282s 564ms/step - acc: 0.8098 - auc: 0.8901 - loss: 0.4176 - val_acc: 0.8467 - val_auc: 0.9243 - val_loss: 0.3627\n",
    "Epoch 1/3\n",
    "2273/2273 ━━━━━━━━━━━━━━━━━━━━ 1570s 686ms/step - acc: 0.8249 - auc: 0.9053 - loss: 0.3890 - val_acc: 0.9021 - val_auc: 0.9657 - val_loss: 0.2496\n",
    "Epoch 2/3\n",
    "2273/2273 ━━━━━━━━━━━━━━━━━━━━ 1538s 677ms/step - acc: 0.8882 - auc: 0.9564 - loss: 0.2694 - val_acc: 0.9313 - val_auc: 0.9814 - val_loss: 0.1841\n",
    "Epoch 3/3\n",
    "2273/2273 ━━━━━━━━━━━━━━━━━━━━ 1522s 670ms/step - acc: 0.9134 - auc: 0.9729 - loss: 0.2139 - val_acc: 0.9429 - val_auc: 0.9879 - val_loss: 0.1507\n",
    "\n",
    " AC->B {'auc': 0.5179217232017711, 'bal_acc': 0.5132683126820073, 'f1': 0.5412313271738192, 'precision': 0.50810635538262, 'recall': 0.5789765379641604}\n",
    "threshold: 0.3499999999999999\n",
    "confusion matrix [[TN FP],[FN TP]]:\n",
    " [[2458 3034]\n",
    " [2279 3134]]\n",
    "Epoch 1/3\n",
    "3512/3512 ━━━━━━━━━━━━━━━━━━━━ 2000s 568ms/step - acc: 0.7692 - auc: 0.8514 - loss: 0.4771 - val_acc: 0.8074 - val_auc: 0.8899 - val_loss: 0.4234\n",
    "Epoch 2/3\n",
    "3512/3512 ━━━━━━━━━━━━━━━━━━━━ 1959s 558ms/step - acc: 0.7842 - auc: 0.8665 - loss: 0.4549 - val_acc: 0.8115 - val_auc: 0.8940 - val_loss: 0.4184\n",
    "Epoch 3/3\n",
    "3512/3512 ━━━━━━━━━━━━━━━━━━━━ 1971s 561ms/step - acc: 0.7866 - auc: 0.8688 - loss: 0.4513 - val_acc: 0.8134 - val_auc: 0.8963 - val_loss: 0.4142\n",
    "Epoch 1/3\n",
    "3512/3512 ━━━━━━━━━━━━━━━━━━━━ 2393s 679ms/step - acc: 0.8261 - auc: 0.9101 - loss: 0.3784 - val_acc: 0.9056 - val_auc: 0.9675 - val_loss: 0.2345\n",
    "Epoch 2/3\n",
    "3512/3512 ━━━━━━━━━━━━━━━━━━━━ 2324s 662ms/step - acc: 0.8980 - auc: 0.9636 - loss: 0.2442 - val_acc: 0.9296 - val_auc: 0.9810 - val_loss: 0.1781\n",
    "Epoch 3/3\n",
    "3512/3512 ━━━━━━━━━━━━━━━━━━━━ 2371s 675ms/step - acc: 0.9159 - auc: 0.9745 - loss: 0.2040 - val_acc: 0.9394 - val_auc: 0.9859 - val_loss: 0.1529\n",
    "\n",
    " BC->A {'auc': 0.9723292243594156, 'bal_acc': 0.9270961282602148, 'f1': 0.9278915229885057, 'precision': 0.9484167049105094, 'recall': 0.9082359145644722}\n",
    "threshold: 0.41999999999999993\n",
    "confusion matrix [[TN FP],[FN TP]]:\n",
    " [[ 9837   562]\n",
    " [ 1044 10333]]\n",
    "auc mean±std = 0.6334099715365208 ± 0.24367000171272593\n",
    "bal_acc mean±std = 0.6490667167400302 ± 0.19661402094685215\n",
    "f1 mean±std = 0.6101895444316184 ± 0.2363353843527968\n",
    "precision mean±std = 0.559817665532954 ± 0.29842733068900634\n",
    "recall mean±std = 0.813919302358029 ± 0.1672019144210321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d4f8720-1884-42e2-86fe-25b9ee5d4664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "WARNING:tensorflow:From C:\\Users\\blend\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/3\n",
      "\u001b[1m5761/5761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1227s\u001b[0m 212ms/step - acc: 0.7074 - auc: 0.7799 - loss: 0.5622 - val_acc: 0.7539 - val_auc: 0.8425 - val_loss: 0.5023\n",
      "Epoch 2/3\n",
      "\u001b[1m5761/5761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1218s\u001b[0m 211ms/step - acc: 0.7213 - auc: 0.7966 - loss: 0.5459 - val_acc: 0.7537 - val_auc: 0.8450 - val_loss: 0.4976\n",
      "Epoch 3/3\n",
      "\u001b[1m5761/5761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1220s\u001b[0m 212ms/step - acc: 0.7223 - auc: 0.7970 - loss: 0.5456 - val_acc: 0.7649 - val_auc: 0.8485 - val_loss: 0.4941\n",
      "Epoch 1/3\n",
      "\u001b[1m5761/5761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1431s\u001b[0m 247ms/step - acc: 0.7793 - auc: 0.8634 - loss: 0.4584 - val_acc: 0.8810 - val_auc: 0.9528 - val_loss: 0.2874\n",
      "Epoch 2/3\n",
      "\u001b[1m5761/5761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1426s\u001b[0m 248ms/step - acc: 0.8752 - auc: 0.9484 - loss: 0.2912 - val_acc: 0.9182 - val_auc: 0.9753 - val_loss: 0.2056\n",
      "Epoch 3/3\n",
      "\u001b[1m3493/5761\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m7:45\u001b[0m 205ms/step - acc: 0.8945 - auc: 0.9613 - loss: 0.2520"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " AB->D {'auc': 0.4821745839767928, 'bal_acc': 0.4872513365181538, 'f1': 0.41660987474443634, 'precision': 0.38776849380987793, 'recall': 0.45008632070681426}\n",
      "threshold: 0.4599999999999999\n",
      "confusion matrix [[TN FP],[FN TP]]:\n",
      " [[46296 41985]\n",
      " [32490 26592]]\n",
      "Epoch 1/3\n",
      "\u001b[1m15371/15371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3438s\u001b[0m 223ms/step - acc: 0.7839 - auc: 0.7920 - loss: 0.4483 - val_acc: 0.7942 - val_auc: 0.8394 - val_loss: 0.4176\n",
      "Epoch 2/3\n",
      "\u001b[1m15371/15371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3386s\u001b[0m 220ms/step - acc: 0.7856 - auc: 0.7980 - loss: 0.4443 - val_acc: 0.7968 - val_auc: 0.8434 - val_loss: 0.4119\n",
      "Epoch 3/3\n",
      "\u001b[1m15371/15371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3373s\u001b[0m 219ms/step - acc: 0.7862 - auc: 0.7987 - loss: 0.4434 - val_acc: 0.8017 - val_auc: 0.8428 - val_loss: 0.4097\n",
      "Epoch 1/3\n",
      "\u001b[1m15371/15371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3995s\u001b[0m 259ms/step - acc: 0.8290 - auc: 0.8784 - loss: 0.3601 - val_acc: 0.8870 - val_auc: 0.9455 - val_loss: 0.2540\n",
      "Epoch 2/3\n",
      "\u001b[1m15371/15371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3982s\u001b[0m 259ms/step - acc: 0.8800 - auc: 0.9376 - loss: 0.2666 - val_acc: 0.9102 - val_auc: 0.9640 - val_loss: 0.2091\n",
      "Epoch 3/3\n",
      "\u001b[1m15371/15371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3914s\u001b[0m 255ms/step - acc: 0.8984 - auc: 0.9540 - loss: 0.2308 - val_acc: 0.9190 - val_auc: 0.9718 - val_loss: 0.1921\n",
      "\n",
      " AD->B {'auc': 0.48283331756827763, 'bal_acc': 0.4902362894808686, 'f1': 0.4949127906976744, 'precision': 0.4868632707774799, 'recall': 0.5032329576944393}\n",
      "threshold: 0.5499999999999999\n",
      "confusion matrix [[TN FP],[FN TP]]:\n",
      " [[2621 2871]\n",
      " [2689 2724]]\n",
      "Epoch 1/3\n",
      "\u001b[1m16611/16611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3648s\u001b[0m 219ms/step - acc: 0.7917 - auc: 0.8202 - loss: 0.4330 - val_acc: 0.8054 - val_auc: 0.8512 - val_loss: 0.4054\n",
      "Epoch 2/3\n",
      "\u001b[1m16611/16611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3629s\u001b[0m 218ms/step - acc: 0.7931 - auc: 0.8243 - loss: 0.4295 - val_acc: 0.8027 - val_auc: 0.8511 - val_loss: 0.4065\n",
      "Epoch 1/3\n",
      "\u001b[1m16611/16611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4455s\u001b[0m 268ms/step - acc: 0.8330 - auc: 0.8902 - loss: 0.3506 - val_acc: 0.8852 - val_auc: 0.9459 - val_loss: 0.2569\n",
      "Epoch 2/3\n",
      "\u001b[1m16611/16611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4423s\u001b[0m 266ms/step - acc: 0.8840 - auc: 0.9428 - loss: 0.2606 - val_acc: 0.9083 - val_auc: 0.9641 - val_loss: 0.2126\n",
      "Epoch 3/3\n",
      "\u001b[1m 4863/16611\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43:33\u001b[0m 222ms/step - acc: 0.8945 - auc: 0.9520 - loss: 0.2393"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_y_true(ds):\n",
    "    return np.concatenate([y.numpy().reshape(-1) for _, y in ds]).astype(int)\n",
    "\n",
    "def get_y_prob(model, ds):\n",
    "    return model.predict(ds, verbose=0).reshape(-1)\n",
    "\n",
    "# Dataset units\n",
    "A_train = (train_dir_A, train_labels_A)\n",
    "A_test  = (test_dir_A,  test_labels_A)\n",
    "B_train = (train_dir_B, train_labels_B)\n",
    "B_test  = (test_dir_B,  test_labels_B)\n",
    "D_train = (train_dir_D, train_labels_D)\n",
    "D_test  = (test_dir_D,  test_labels_D)\n",
    "\n",
    "folds = [\n",
    "    ([A_train, B_train], D_test, \"AB->D\"),\n",
    "    ([A_train, D_train], B_test, \"AD->B\"),\n",
    "    ([B_train, D_train], A_test, \"BD->A\"),\n",
    "]\n",
    "\n",
    "results = []\n",
    "for train_pairs, test_pair, name in folds:\n",
    "    train_ds, val_ds, test_ds = build_fold(train_pairs, test_pair)\n",
    "\n",
    "    r = run_fold(train_ds, val_ds, test_ds)   # <- r must include r[\"model\"] and r[\"thr\"][\"t\"] (or pick 0.5)\n",
    "    r[\"fold\"] = name\n",
    "\n",
    "    model = r[\"model\"]\n",
    "    thr = r[\"thr\"][\"t\"] if isinstance(r.get(\"thr\"), dict) and \"t\" in r[\"thr\"] else 0.5\n",
    "\n",
    "    y_true = get_y_true(test_ds)\n",
    "    y_prob = get_y_prob(model, test_ds)\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    r[\"cm\"] = cm\n",
    "\n",
    "    results.append(r)\n",
    "\n",
    "    print(\"\\n\", name, {k: r[k] for k in [\"auc\",\"bal_acc\",\"f1\",\"precision\",\"recall\"] if k in r})\n",
    "    print(\"threshold:\", thr)\n",
    "    print(\"confusion matrix [[TN FP],[FN TP]]:\\n\", cm)\n",
    "\n",
    "# average\n",
    "for k in [\"auc\",\"bal_acc\",\"f1\",\"precision\",\"recall\"]:\n",
    "    vals = [r[k] for r in results]\n",
    "    print(k, \"mean±std =\", float(np.mean(vals)), \"±\", float(np.std(vals)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a79280c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m 2999/18871\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m49:47\u001b[0m 188ms/step - acc: 0.7400 - auc: 0.7366 - loss: 0.5242"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16113/18871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m8:53\u001b[0m 193ms/step - acc: 0.7581 - auc: 0.7890 - loss: 0.4877"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18871/18871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5079s\u001b[0m 269ms/step - acc: 0.8093 - auc: 0.8726 - loss: 0.3935 - val_acc: 0.8736 - val_auc: 0.9404 - val_loss: 0.2817\n",
      "Epoch 2/5\n",
      "\u001b[1m18871/18871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5230s\u001b[0m 277ms/step - acc: 0.8717 - auc: 0.9368 - loss: 0.2860 - val_acc: 0.9043 - val_auc: 0.9636 - val_loss: 0.2222\n",
      "Epoch 3/5\n",
      "\u001b[1m18871/18871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5238s\u001b[0m 278ms/step - acc: 0.8940 - auc: 0.9553 - loss: 0.2423 - val_acc: 0.9190 - val_auc: 0.9730 - val_loss: 0.1919\n",
      "Epoch 4/5\n",
      "\u001b[1m18871/18871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5279s\u001b[0m 280ms/step - acc: 0.9066 - auc: 0.9645 - loss: 0.2166 - val_acc: 0.9266 - val_auc: 0.9778 - val_loss: 0.1763\n",
      "Epoch 5/5\n",
      "\u001b[1m18871/18871\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5272s\u001b[0m 279ms/step - acc: 0.9155 - auc: 0.9704 - loss: 0.1982 - val_acc: 0.9332 - val_auc: 0.9810 - val_loss: 0.1606\n",
      "FINAL threshold: {'t': 0.4699999999999999, 'f1': 0.8853883511709109, 'precision': 0.8789603233746585, 'recall': 0.8919110907424381, 'bal_acc': 0.9209853605173133}\n"
     ]
    }
   ],
   "source": [
    "# --- FINAL TRAIN POOL: A+B+D (train splits only) ---\n",
    "ALL_train_paths  = train_dir_A + train_dir_B + train_dir_D\n",
    "ALL_train_labels = train_labels_A + train_labels_B + train_labels_D\n",
    "\n",
    "# internal split for early stopping + threshold calibration\n",
    "trp, try_, vap, vay = split_train_val(ALL_train_paths, ALL_train_labels)\n",
    "\n",
    "final_train_ds = make_ds(trp, try_, training=True)\n",
    "final_val_ds   = make_ds(vap, vay, training=False)\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
    "\n",
    "base = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(256,256,3))\n",
    "base.trainable = False\n",
    "\n",
    "final_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input((256,256,3)),\n",
    "    tf.keras.layers.Lambda(preprocess_input),\n",
    "    base,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "def compile_final(lr):\n",
    "    final_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[tf.keras.metrics.AUC(name=\"auc\"),\n",
    "                 tf.keras.metrics.BinaryAccuracy(name=\"acc\", threshold=0.5)]\n",
    "    )\n",
    "\n",
    "# stage 1\n",
    "compile_final(1e-3)\n",
    "final_model.fit(\n",
    "    final_train_ds,\n",
    "    validation_data=final_val_ds,\n",
    "    epochs=5,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=1, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "# stage 2 fine-tune\n",
    "base.trainable = True\n",
    "for layer in base.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "compile_final(1e-5)\n",
    "final_model.fit(\n",
    "    final_train_ds,\n",
    "    validation_data=final_val_ds,\n",
    "    epochs=5,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=1, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "\n",
    "# threshold calibrated on internal validation set\n",
    "final_thr = best_threshold_on_val(final_model, final_val_ds)\n",
    "print(\"FINAL threshold:\", final_thr)\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "Path(\"Models\").mkdir(exist_ok=True)\n",
    "\n",
    "# save model\n",
    "final_model.save(\"Models/deepfake_model.keras\")\n",
    "final_model.save_weights(\"Models/deepfake_model_weights.weights.h5\")\n",
    "\n",
    "# save threshold + val metrics (so your app can use the same threshold)\n",
    "with open(\"Models/threshold.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_thr, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba7445ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: C:\\Users\\blend\\inzynierka\\Models\\deepfake_model.keras\n",
      "Saved weights: C:\\Users\\blend\\inzynierka\\Models\\deepfake_model_weights.weights.h5\n",
      "Saved threshold: C:\\Users\\blend\\inzynierka\\Models\\threshold.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "SAVE_DIR = Path(r\"C:\\Users\\blend\\inzynierka\\Models\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_path   = SAVE_DIR / \"deepfake_model.keras\"\n",
    "weights_path = SAVE_DIR / \"deepfake_model_weights.weights.h5\"\n",
    "thr_path     = SAVE_DIR / \"threshold.json\"\n",
    "\n",
    "final_model.save(model_path)\n",
    "final_model.save_weights(weights_path)\n",
    "\n",
    "with open(thr_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_thr, f, indent=2)\n",
    "\n",
    "print(\"Saved model:\", model_path)\n",
    "print(\"Saved weights:\", weights_path)\n",
    "print(\"Saved threshold:\", thr_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b112a564-9fd3-4ac0-a742-bd1a436ccdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL_MODEL on final_val_ds ===\n",
      "N = 150968 | threshold = 0.4699999999999999\n",
      "AUC           : 0.9810642976580832\n",
      "Accuracy      : 0.9332507551269144\n",
      "Balanced Acc. : 0.9209853605173133\n",
      "Precision     : 0.8789603233746585\n",
      "Recall        : 0.8919110907424381\n",
      "F1            : 0.8853883511709109\n",
      "Confusion matrix [[TN FP],[FN TP]]:\n",
      " [[101968   5360]\n",
      " [  4717  38923]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake     0.9558    0.9501    0.9529    107328\n",
      "        real     0.8790    0.8919    0.8854     43640\n",
      "\n",
      "    accuracy                         0.9333    150968\n",
      "   macro avg     0.9174    0.9210    0.9192    150968\n",
      "weighted avg     0.9336    0.9333    0.9334    150968\n",
      "\n",
      "mean p(real) for true=0(fake): 0.07366536557674408\n",
      "mean p(real) for true=1(real): 0.8244510293006897\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, balanced_accuracy_score,\n",
    "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "def eval_binary(model, ds, thr=0.5, title=\"EVAL\"):\n",
    "    # y_true\n",
    "    y_true = np.concatenate([y.numpy().reshape(-1) for _, y in ds], axis=0).astype(int)\n",
    "    # probabilities p(class=1) = p(real) u Ciebie\n",
    "    y_prob = model.predict(ds, verbose=0).reshape(-1)\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    print(\"N =\", len(y_true), \"| threshold =\", thr)\n",
    "    print(\"AUC           :\", roc_auc_score(y_true, y_prob))\n",
    "    print(\"Accuracy      :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Balanced Acc. :\", balanced_accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision     :\", precision_score(y_true, y_pred, zero_division=0))\n",
    "    print(\"Recall        :\", recall_score(y_true, y_pred, zero_division=0))\n",
    "    print(\"F1            :\", f1_score(y_true, y_pred, zero_division=0))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    print(\"Confusion matrix [[TN FP],[FN TP]]:\\n\", cm)\n",
    "\n",
    "    # Twoje klasy: 0=fake, 1=real\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"fake\",\"real\"], digits=4, zero_division=0))\n",
    "\n",
    "    # pomocniczo: średnie prawdopodobieństwa\n",
    "    print(\"mean p(real) for true=0(fake):\", float(np.mean(y_prob[y_true==0])) if np.any(y_true==0) else None)\n",
    "    print(\"mean p(real) for true=1(real):\", float(np.mean(y_prob[y_true==1])) if np.any(y_true==1) else None)\n",
    "\n",
    "    return {\"y_true\": y_true, \"y_prob\": y_prob, \"y_pred\": y_pred, \"cm\": cm}\n",
    "\n",
    "# wybór progu:\n",
    "thr = final_thr[\"t\"] if isinstance(globals().get(\"final_thr\", None), dict) and \"t\" in final_thr else 0.5\n",
    "\n",
    "# Walidacja (z której kalibrowałeś próg)\n",
    "val_out = eval_binary(final_model, final_val_ds, thr=thr, title=\"FINAL_MODEL on final_val_ds\")\n",
    "\n",
    "# Jeśli masz osobny test_ds (np. A_test/B_test/D_test albo final_test_ds), odkomentuj i podstaw:\n",
    "# test_out = eval_binary(final_model, final_test_ds, thr=thr, title=\"FINAL_MODEL on TEST\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "080e17c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys, tensorflow as tf, keras\n",
    "# print(\"python:\", sys.executable)\n",
    "# print(\"tf:\", tf.__version__)\n",
    "# print(\"keras:\", keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1969690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ===== CNN (baseline) =====\n",
    "# TH = 0.5  # próg klasyfikacji\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Input(shape=(256, 256, 3)),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "#     tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\"),\n",
    "#     tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "#     tf.keras.layers.GlobalAveragePooling2D(),\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "#     tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "# ])\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "#     loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "#     metrics=[\n",
    "#         tf.keras.metrics.BinaryAccuracy(name=\"acc\", threshold=TH),\n",
    "#         tf.keras.metrics.Precision(name=\"precision\", thresholds=TH),\n",
    "#         tf.keras.metrics.Recall(name=\"recall\", thresholds=TH),\n",
    "#         tf.keras.metrics.AUC(name=\"auc\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# # ===== Trening (na start krótko) =====\n",
    "# history = model.fit(\n",
    "#     model_train,\n",
    "#     validation_data=model_val,\n",
    "#     epochs=3,\n",
    "#     callbacks=[\n",
    "#         tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=1, restore_best_weights=True)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # ===== Ewaluacja na teście =====\n",
    "# print(\"\\nTEST (Keras metrics):\")\n",
    "# print(dict(zip(model.metrics_names, model.evaluate(model_test, return_dict=True, verbose=0))))\n",
    "\n",
    "# # ===== Dodatkowe metryki: confusion matrix, report, ROC-AUC =====\n",
    "# y_true = np.concatenate([y.numpy().reshape(-1) for _, y in model_test], axis=0)\n",
    "# y_prob = model.predict(model_test, verbose=0).reshape(-1)\n",
    "# y_pred = (y_prob >= TH).astype(int)\n",
    "\n",
    "# try:\n",
    "#     from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "#     cm = confusion_matrix(y_true, y_pred)\n",
    "#     print(\"\\nConfusion matrix:\\n\", cm)\n",
    "\n",
    "#     # class_names: np. ['fake','real'] => 0->fake, 1->real\n",
    "#     print(\"\\nClassification report:\\n\",\n",
    "#           classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "#     print(\"ROC-AUC:\", roc_auc_score(y_true, y_prob))\n",
    "# except Exception as e:\n",
    "#     print(\"Brak sklearn lub błąd w metrykach dodatkowych:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c18d66a",
   "metadata": {},
   "source": [
    "Model: \"sequential\"\n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ conv2d (Conv2D)                 │ (None, 256, 256, 32)   │           896 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ max_pooling2d (MaxPooling2D)    │ (None, 128, 128, 32)   │             0 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ conv2d_1 (Conv2D)               │ (None, 128, 128, 64)   │        18,496 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ max_pooling2d_1 (MaxPooling2D)  │ (None, 64, 64, 64)     │             0 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ conv2d_2 (Conv2D)               │ (None, 64, 64, 128)    │        73,856 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ max_pooling2d_2 (MaxPooling2D)  │ (None, 32, 32, 128)    │             0 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ global_average_pooling2d        │ (None, 128)            │             0 │\n",
    "│ (GlobalAveragePooling2D)        │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None, 128)            │             0 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense (Dense)                   │ (None, 1)              │           129 │\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
    " Total params: 93,377 (364.75 KB)\n",
    " Trainable params: 93,377 (364.75 KB)\n",
    " Non-trainable params: 0 (0.00 B)\n",
    "Epoch 1/3\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 853s 377ms/step - acc: 0.5680 - auc: 0.5908 - loss: 0.6810 - precision: 0.5655 - recall: 0.8652 - val_acc: 0.5925 - val_auc: 0.6338 - val_loss: 0.6744 - val_precision: 0.6447 - val_recall: 0.5411\n",
    "Epoch 2/3\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 863s 382ms/step - acc: 0.6122 - auc: 0.6464 - loss: 0.6612 - precision: 0.6290 - recall: 0.6880 - val_acc: 0.6326 - val_auc: 0.6925 - val_loss: 0.6503 - val_precision: 0.6102 - val_recall: 0.8789\n",
    "Epoch 3/3\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 864s 382ms/step - acc: 0.6526 - auc: 0.7003 - loss: 0.6313 - precision: 0.6686 - recall: 0.7082 - val_acc: 0.6061 - val_auc: 0.7240 - val_loss: 0.6571 - val_precision: 0.5808 - val_recall: 0.9643\n",
    "\n",
    "TEST (Keras metrics):\n",
    "{'loss': 0.7267244458198547, 'compile_metrics': 0.4897134602069855}\n",
    "\n",
    "Confusion matrix:\n",
    " [[3630 6769]\n",
    " [4343 7034]]\n",
    "\n",
    "Classification report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "        fake     0.4553    0.3491    0.3952     10399\n",
    "        real     0.5096    0.6183    0.5587     11377\n",
    "\n",
    "    accuracy                         0.4897     21776\n",
    "   macro avg     0.4824    0.4837    0.4769     21776\n",
    "weighted avg     0.4837    0.4897    0.4806     21776\n",
    "\n",
    "ROC-AUC: 0.4987999138496348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "149ade73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
    "# from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "# TH = 0.45\n",
    "\n",
    "# base = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(256,256,3))\n",
    "# base.trainable = False\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Input((256,256,3)),\n",
    "#     tf.keras.layers.Lambda(preprocess_input),\n",
    "#     base,\n",
    "#     tf.keras.layers.GlobalAveragePooling2D(),\n",
    "#     tf.keras.layers.Dropout(0.3),\n",
    "#     tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "# ])\n",
    "\n",
    "# def compile_model(lr):\n",
    "#     model.compile(\n",
    "#         optimizer=tf.keras.optimizers.Adam(lr),\n",
    "#         loss=\"binary_crossentropy\",\n",
    "#         metrics=[\n",
    "#             tf.keras.metrics.BinaryAccuracy(name=\"acc\", threshold=TH),\n",
    "#             tf.keras.metrics.Precision(name=\"precision\", thresholds=TH),\n",
    "#             tf.keras.metrics.Recall(name=\"recall\", thresholds=TH),\n",
    "#             tf.keras.metrics.AUC(name=\"auc\"),\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "# # ---- Stage 1: train head (feature extractor) ----\n",
    "# compile_model(1e-3)\n",
    "# history_1 = model.fit(\n",
    "#     model_train,\n",
    "#     validation_data=model_val,\n",
    "#     epochs=3,\n",
    "#     callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=1, restore_best_weights=True)]\n",
    "# )\n",
    "\n",
    "# # ---- Stage 2: fine-tuning ----\n",
    "# base.trainable = True\n",
    "# for layer in base.layers[:-30]:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# compile_model(1e-5)\n",
    "# history_2 = model.fit(\n",
    "#     model_train,\n",
    "#     validation_data=model_val,\n",
    "#     epochs=3,\n",
    "#     callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=1, restore_best_weights=True)]\n",
    "# )\n",
    "\n",
    "# # ---- Final test evaluation ----\n",
    "# print(\"Test (Keras):\", model.evaluate(model_test, return_dict=True, verbose=0))\n",
    "\n",
    "# y_true = np.concatenate([y.numpy().reshape(-1) for _, y in model_test], axis=0)\n",
    "# y_prob = model.predict(model_test, verbose=0).reshape(-1)\n",
    "# y_pred = (y_prob >= TH).astype(int)\n",
    "\n",
    "# print(\"ROC-AUC:\", roc_auc_score(y_true, y_prob))\n",
    "# print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "# print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794edba6",
   "metadata": {},
   "source": [
    "Epoch 1/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1253s 552ms/step - acc: 0.7688 - auc: 0.8620 - loss: 0.4654 - precision: 0.7410 - recall: 0.8793 - val_acc: 0.8344 - val_auc: 0.9120 - val_loss: 0.3980 - val_precision: 0.8422 - val_recall: 0.8522\n",
    "Epoch 2/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1193s 528ms/step - acc: 0.8017 - auc: 0.8900 - loss: 0.4174 - precision: 0.7816 - recall: 0.8784 - val_acc: 0.8428 - val_auc: 0.9222 - val_loss: 0.3664 - val_precision: 0.8284 - val_recall: 0.8932\n",
    "Epoch 3/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1252s 554ms/step - acc: 0.8072 - auc: 0.8936 - loss: 0.4104 - precision: 0.7877 - recall: 0.8806 - val_acc: 0.8525 - val_auc: 0.9280 - val_loss: 0.3586 - val_precision: 0.8524 - val_recall: 0.8783\n",
    "Epoch 4/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1247s 551ms/step - acc: 0.8074 - auc: 0.8950 - loss: 0.4075 - precision: 0.7899 - recall: 0.8766 - val_acc: 0.8543 - val_auc: 0.9300 - val_loss: 0.3519 - val_precision: 0.8502 - val_recall: 0.8855\n",
    "Epoch 5/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1231s 545ms/step - acc: 0.8095 - auc: 0.8955 - loss: 0.4067 - precision: 0.7917 - recall: 0.8785 - val_acc: 0.8527 - val_auc: 0.9297 - val_loss: 0.3486 - val_precision: 0.8416 - val_recall: 0.8951\n",
    "Epoch 1/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1502s 660ms/step - acc: 0.8188 - auc: 0.9052 - loss: 0.3917 - precision: 0.7989 - recall: 0.8882 - val_acc: 0.9061 - val_auc: 0.9682 - val_loss: 0.2370 - val_precision: 0.9051 - val_recall: 0.9225\n",
    "Epoch 2/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1474s 652ms/step - acc: 0.8838 - auc: 0.9559 - loss: 0.2683 - precision: 0.8709 - recall: 0.9215 - val_acc: 0.9344 - val_auc: 0.9831 - val_loss: 0.1764 - val_precision: 0.9396 - val_recall: 0.9385\n",
    "Epoch 3/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1493s 661ms/step - acc: 0.9109 - auc: 0.9720 - loss: 0.2149 - precision: 0.9005 - recall: 0.9388 - val_acc: 0.9520 - val_auc: 0.9899 - val_loss: 0.1383 - val_precision: 0.9562 - val_recall: 0.9546\n",
    "Epoch 4/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1469s 650ms/step - acc: 0.9295 - auc: 0.9815 - loss: 0.1755 - precision: 0.9207 - recall: 0.9514 - val_acc: 0.9606 - val_auc: 0.9928 - val_loss: 0.1148 - val_precision: 0.9629 - val_recall: 0.9640\n",
    "Epoch 5/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1425s 630ms/step - acc: 0.9394 - auc: 0.9863 - loss: 0.1505 - precision: 0.9310 - recall: 0.9589 - val_acc: 0.9656 - val_auc: 0.9945 - val_loss: 0.1001 - val_precision: 0.9694 - val_recall: 0.9666\n",
    "Epoch 6/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1469s 650ms/step - acc: 0.9468 - auc: 0.9893 - loss: 0.1327 - precision: 0.9392 - recall: 0.9638 - val_acc: 0.9697 - val_auc: 0.9958 - val_loss: 0.0896 - val_precision: 0.9759 - val_recall: 0.9677\n",
    "Test (Keras): {'acc': 0.5729243159294128, 'auc': 0.6681026220321655, 'loss': 1.969002604484558, 'precision': 0.9001926779747009, 'recall': 0.20532654225826263}\n",
    "ROC-AUC: 0.6697694612203459\n",
    "Confusion matrix:\n",
    " [[10140   259]\n",
    " [ 9041  2336]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        fake     0.5286    0.9751    0.6856     10399\n",
    "        real     0.9002    0.2053    0.3344     11377\n",
    "\n",
    "    accuracy                         0.5729     21776\n",
    "   macro avg     0.7144    0.5902    0.5100     21776\n",
    "weighted avg     0.7228    0.5729    0.5021     21776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06630473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453b7f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3dd125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68302f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f99857ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AB->D ===\n",
      "threshold: 0.46\n",
      "auc:       0.4822\n",
      "bal_acc:   0.4873\n",
      "f1:        0.4166\n",
      "precision: 0.3878\n",
      "recall:    0.4501\n",
      "confusion matrix [[TN FP],[FN TP]]:\n",
      " [[46296 41985]\n",
      " [32490 26592]]\n",
      "\n",
      "=== AD->B ===\n",
      "threshold: 0.55\n",
      "auc:       0.4828\n",
      "bal_acc:   0.4902\n",
      "f1:        0.4949\n",
      "precision: 0.4869\n",
      "recall:    0.5032\n",
      "confusion matrix [[TN FP],[FN TP]]:\n",
      " [[2621 2871]\n",
      " [2689 2724]]\n",
      "\n",
      "=== BD->A ===\n",
      "threshold: 0.45\n",
      "auc:       0.9202\n",
      "bal_acc:   0.8301\n",
      "f1:        0.8497\n",
      "precision: 0.8035\n",
      "recall:    0.9015\n",
      "confusion matrix [[TN FP],[FN TP]]:\n",
      " [[ 7891  2508]\n",
      " [ 1121 10256]]\n",
      "\n",
      "=== MEAN ± STD ===\n",
      "auc        mean±std = 0.6284 ± 0.2064 (n=3)\n",
      "bal_acc    mean±std = 0.6025 ± 0.1609 (n=3)\n",
      "f1         mean±std = 0.5871 ± 0.1884 (n=3)\n",
      "precision  mean±std = 0.5594 ± 0.1773 (n=3)\n",
      "recall     mean±std = 0.6183 ± 0.2014 (n=3)\n"
     ]
    }
   ],
   "source": [
    "#odzyskanie metryk fold\n",
    "import numpy as np\n",
    "\n",
    "# 1) sanity: czy results istnieje\n",
    "if \"results\" not in globals() or len(results) == 0:\n",
    "    raise RuntimeError(\"Nie ma 'results' w pamięci albo jest puste. Jeśli kernel był restartowany, trzeba uruchomić LODO jeszcze raz.\")\n",
    "\n",
    "# 2) wypisz metryki per fold\n",
    "for r in results:\n",
    "    name = r.get(\"fold\", \"?\")\n",
    "    thr = r.get(\"thr\", {}).get(\"t\", 0.5) if isinstance(r.get(\"thr\"), dict) else 0.5\n",
    "    cm = r.get(\"cm\", None)\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"threshold: {thr:.2f}\")\n",
    "    print(f\"auc:       {r.get('auc', float('nan')):.4f}\")\n",
    "    print(f\"bal_acc:   {r.get('bal_acc', float('nan')):.4f}\")\n",
    "    print(f\"f1:        {r.get('f1', float('nan')):.4f}\")\n",
    "    print(f\"precision: {r.get('precision', float('nan')):.4f}\")\n",
    "    print(f\"recall:    {r.get('recall', float('nan')):.4f}\")\n",
    "    if cm is not None:\n",
    "        print(\"confusion matrix [[TN FP],[FN TP]]:\\n\", cm)\n",
    "\n",
    "# 3) średnie ± odchylenie\n",
    "keys = [\"auc\",\"bal_acc\",\"f1\",\"precision\",\"recall\"]\n",
    "print(\"\\n=== MEAN ± STD ===\")\n",
    "for k in keys:\n",
    "    vals = [rr[k] for rr in results if k in rr and rr[k] is not None]\n",
    "    if len(vals):\n",
    "        print(f\"{k:10s} mean±std = {float(np.mean(vals)):.4f} ± {float(np.std(vals)):.4f} (n={len(vals)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f2f3903-6ff2-465a-a996-d0f7389a1b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 3.23 GB  (C:\\Users\\blend\\inzynierka\\Dane\\Dataset_A_extract)\n",
      "B: 1.68 GB  (C:\\Users\\blend\\inzynierka\\Dane\\Dataset_B_extract)\n",
      "C: 0.47 GB  (C:\\Users\\blend\\inzynierka\\Dane\\Dataset_C_extract)\n",
      "D: 46.61 GB  (C:\\Users\\blend\\inzynierka\\Dane\\Dataset_D_extract)\n",
      "\n",
      "SUMA: 51.99 GB\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def dir_size_bytes(root: Path) -> int:\n",
    "    return sum(p.stat().st_size for p in root.rglob(\"*\") if p.is_file())\n",
    "\n",
    "def gb(x_bytes: int) -> float:\n",
    "    return x_bytes / (1024**3)\n",
    "\n",
    "paths = {\n",
    "    \"A\": extract_path_A,\n",
    "    \"B\": extract_path_B,\n",
    "    \"C\": extract_path_C,\n",
    "    \"D\": extract_path_D,\n",
    "}\n",
    "\n",
    "sizes = {}\n",
    "total = 0\n",
    "\n",
    "for k, p in paths.items():\n",
    "    if not p.exists():\n",
    "        print(f\"{k}: MISSING -> {p}\")\n",
    "        sizes[k] = 0\n",
    "        continue\n",
    "\n",
    "    b = dir_size_bytes(p)\n",
    "    sizes[k] = b\n",
    "    total += b\n",
    "    print(f\"{k}: {gb(b):.2f} GB  ({p})\")\n",
    "\n",
    "print(f\"\\nSUMA: {gb(total):.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607a5a38-90e5-4a62-978e-9f7ef756e0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
