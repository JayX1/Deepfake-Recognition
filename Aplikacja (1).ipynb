{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc2ccd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import zipfile\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import numpy as np\n",
    "\n",
    "#Funkcja do rozpakowania plików zip do nowej ścieżki\n",
    "def unzip_file(zip_path: Path, extract_path: Path) -> Path:\n",
    "    extract_path.mkdir(parents=True, exist_ok=True)\n",
    "    # Jeśli katalog nie jest pusty, zakładamy, że już rozpakowane\n",
    "    if any(extract_path.iterdir()):\n",
    "        return extract_path\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "        z.extractall(extract_path)\n",
    "    return extract_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b993807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/datasets/ayushmandatta1/deepdetect-2025/data\n",
    "# Archive-> ddata-> {test,train}-> {real,fake} \n",
    "#--------------------------------------------------------\n",
    "#https://www.kaggle.com/datasets/manjilkarki/deepfake-and-real-images\n",
    "# Dataset-> {test,train,validation}->{real,fake}\n",
    "#--------------------------------------------------------\n",
    "#https://www.kaggle.com/datasets/saurabhbagchi/deepfake-image-detection\n",
    "#indian_deepfakes-> {}\n",
    "#_____________________________________________________________________\n",
    "\n",
    "#Ścieżki do danych w .zip\n",
    "zip_path_A = Path(\"Dane/archive.zip\")\n",
    "zip_path_B = Path(\"Dane/Dataset.zip\")\n",
    "zip_path_C = Path(\"Dane/indian_deepfakes.zip\")\n",
    "\n",
    "#Nowe ścieżki do rozpakowania zip\n",
    "extract_path_A = Path(\"Dane/archive_extract\")\n",
    "extract_path_B = Path(\"Dane/Dataset_extract\")\n",
    "extract_path_C = Path(\"Dane/indian_deepfakes_extract\")\n",
    "\n",
    "#Rozpakowanie\n",
    "unzip_file(zip_path_A,extract_path_A)\n",
    "unzip_file(zip_path_B,extract_path_B)\n",
    "unzip_file(zip_path_C,extract_path_C)\n",
    "\n",
    "train_path_A = extract_path_A / \"ddata\" / \"train\"\n",
    "test_path_A = extract_path_A / \"ddata\" / \"test\"\n",
    "\n",
    "train_path_B = extract_path_B / \"Train\"\n",
    "test_path_B = extract_path_B / \"Test\"\n",
    "\n",
    "train_path_C = extract_path_C /\"indian_deepfakes\" /\"train\"\n",
    "test_path_C = extract_path_C / \"indian_deepfakes\"/\"test\" / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4fee796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad A train/test: 2 0\n",
      "Bad B train/test: 0 0\n",
      "Bad C train/test: 0 0\n"
     ]
    }
   ],
   "source": [
    "#Akceptowane formaty plików\n",
    "EXTS = {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"}\n",
    "LABEL_MAP = {\"fake\": 0.0, \"real\": 1.0}\n",
    "\n",
    "#Sprawdzanie czy tensorflow potrafi poprawnie odczytać zdjęcie\n",
    "def tf_ok(p: Path) -> bool:\n",
    "    try:\n",
    "        b = tf.io.read_file(str(p))\n",
    "        _ = tf.io.decode_image(b, channels=3, expand_animations=False)\n",
    "        return True\n",
    "    except (tf.errors.InvalidArgumentError, tf.errors.DataLossError, tf.errors.NotFoundError):\n",
    "        return False\n",
    "\n",
    "#przetworzenie plików ze ścieżek w listy poprawnych zdjęć i ich etykiet oraz odpadów\n",
    "def collect_good(root: Path, fake_dir=\"fake\", real_dir=\"real\"):\n",
    "    fake_folder = root / fake_dir\n",
    "    real_folder = root / real_dir\n",
    "    if not fake_folder.exists() or not real_folder.exists():\n",
    "        raise FileNotFoundError(f\"Expected {fake_folder} and {real_folder}\")\n",
    "\n",
    "    paths, labels, bad = [], [], 0\n",
    "    for folder, lab in [(fake_folder, LABEL_MAP[\"fake\"]), (real_folder, LABEL_MAP[\"real\"])]:\n",
    "        for p in folder.rglob(\"*\"):\n",
    "            if p.is_file() and p.suffix.lower() in EXTS:\n",
    "                if tf_ok(p):\n",
    "                    paths.append(str(p))\n",
    "                    labels.append(lab)\n",
    "                else:\n",
    "                    bad += 1\n",
    "    return paths, labels, bad\n",
    "\n",
    "\n",
    "#Listy train/test i odpady\n",
    "train_dir_A, train_labels_A, bad_train_A = collect_good(train_path_A)\n",
    "test_dir_A,  test_labels_A,  bad_test_A  = collect_good(test_path_A)\n",
    "\n",
    "train_dir_B, train_labels_B, bad_train_B = collect_good(train_path_B, \"Fake\", \"Real\")\n",
    "test_dir_B,  test_labels_B,  bad_test_B  = collect_good(test_path_B, \"Fake\", \"Real\")\n",
    "\n",
    "train_dir_C, train_labels_C, bad_train_C = collect_good(train_path_C)\n",
    "test_dir_C,  test_labels_C,  bad_test_C  = collect_good(test_path_C)\n",
    "\n",
    "#Raport ile odpadów\n",
    "print(\"Bad A train/test:\", bad_train_A, bad_test_A)\n",
    "print(\"Bad B train/test:\", bad_train_B, bad_test_B)\n",
    "print(\"Bad C train/test:\", bad_train_C, bad_test_C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac98496",
   "metadata": {},
   "source": [
    "Bad A train/test: 2 0\n",
    "Bad B train/test: 0 0\n",
    "Bad C train/test: 0 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aee97cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deklarowanie parametrów\n",
    "IMG_SIZE=(256,256);\n",
    "BATCH=32;\n",
    "SEED=42;\n",
    "VAL_SPLIT=0.2\n",
    "AUTOTUNE=tf.data.AUTOTUNE #Wbudowana optymalizacja CPU/GPU dla tensorflow\n",
    "\n",
    "#Tworzenie tensorflow dataset do szybkiego czytania obrazów \n",
    "def make_ds(paths, labels, training: bool):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    #Tasowanie danych dla treningu\n",
    "    if training:\n",
    "        ds = ds.shuffle(min(len(paths), 20000), seed=SEED, reshuffle_each_iteration=True)\n",
    "\n",
    "        \n",
    "    def load(path, label):\n",
    "        #Dekoduje obraz ze ścieżki w RGB i zamraża GIF\n",
    "        img = tf.io.decode_image(tf.io.read_file(path), channels=3, expand_animations=False)\n",
    "        #Resize do 256x256\n",
    "        img = tf.image.resize(img, IMG_SIZE)\n",
    "        #konwersja na float na potrzeby uczenia mdelu\n",
    "        img = tf.cast(img, tf.float32)  # keep 0..255 for EfficientNet preprocess_input\n",
    "        #Reshpe dla Dense(1, sigmoid) i loss binary_crossentropy\n",
    "        return img, tf.reshape(label, (1,))\n",
    "    #Wielowątkowe ładowanie dla batcha po 32 obrazy\n",
    "    return ds.map(load, num_parallel_calls=AUTOTUNE).batch(BATCH).prefetch(AUTOTUNE)\n",
    "\n",
    "#Split na dane treningowe i walidacyjne\n",
    "def split_train_val(paths, labels):\n",
    "    n = len(paths)\n",
    "    idx = tf.random.shuffle(tf.range(n), seed=SEED).numpy()\n",
    "    cut = int(n*(1-VAL_SPLIT))\n",
    "    tr, va = idx[:cut], idx[cut:]\n",
    "    tr_paths  = [paths[i] for i in tr]; tr_labels = [labels[i] for i in tr]\n",
    "    va_paths  = [paths[i] for i in va]; va_labels = [labels[i] for i in va]\n",
    "    return tr_paths, tr_labels, va_paths, va_labels\n",
    "\n",
    "#Tworzenie folda na potrzeby LODO\n",
    "def build_fold(train_pairs, test_pair):\n",
    "    # train_pairs: list of (train_paths, train_labels) for 2 datasets\n",
    "    # test_pair:   (test_paths, test_labels) for held-out dataset\n",
    "    train_paths = sum([p for p,_ in train_pairs], [])\n",
    "    train_labels= sum([y for _,y in train_pairs], [])\n",
    "\n",
    "    trp, try_, vap, vay = split_train_val(train_paths, train_labels)\n",
    "\n",
    "    train_ds = make_ds(trp, try_, True)\n",
    "    val_ds   = make_ds(vap, vay, False)\n",
    "\n",
    "    test_paths, test_labels = test_pair\n",
    "    test_ds  = make_ds(test_paths, test_labels, False)\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8760c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "def probs_and_labels(ds, model):\n",
    "    y_true = np.concatenate([y.numpy().reshape(-1) for _, y in ds], axis=0).astype(int)\n",
    "    y_prob = model.predict(ds, verbose=0).reshape(-1)\n",
    "    return y_true, y_prob\n",
    "\n",
    "def best_threshold_on_val(model, val_ds):\n",
    "    yv, pv = probs_and_labels(val_ds, model)\n",
    "    ths = np.linspace(0.05, 0.95, 91)\n",
    "    best = {\"t\": 0.5, \"f1\": -1}\n",
    "    for t in ths:\n",
    "        pred = (pv >= t).astype(int)\n",
    "        f1 = f1_score(yv, pred)\n",
    "        if f1 > best[\"f1\"]:\n",
    "            best = {\n",
    "                \"t\": float(t),\n",
    "                \"f1\": float(f1),\n",
    "                \"precision\": float(precision_score(yv, pred)),\n",
    "                \"recall\": float(recall_score(yv, pred)),\n",
    "                \"bal_acc\": float(balanced_accuracy_score(yv, pred)),\n",
    "            }\n",
    "    return best\n",
    "\n",
    "def run_fold(train_ds, val_ds, test_ds):\n",
    "    base = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(256,256,3))\n",
    "    base.trainable = False\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input((256,256,3)),\n",
    "        tf.keras.layers.Lambda(preprocess_input),\n",
    "        base,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    def compile_model(lr):\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(lr),\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[tf.keras.metrics.AUC(name=\"auc\"),\n",
    "                     tf.keras.metrics.BinaryAccuracy(name=\"acc\", threshold=0.5)]\n",
    "        )\n",
    "\n",
    "    # stage 1\n",
    "    compile_model(1e-3)\n",
    "    model.fit(train_ds, validation_data=val_ds, epochs=3,\n",
    "              callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=1, restore_best_weights=True)])\n",
    "\n",
    "    # stage 2 fine-tune\n",
    "    base.trainable = True\n",
    "    for layer in base.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    compile_model(1e-5)\n",
    "    model.fit(train_ds, validation_data=val_ds, epochs=3,\n",
    "              callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=1, restore_best_weights=True)])\n",
    "\n",
    "    # threshold on val\n",
    "    th = best_threshold_on_val(model, val_ds)\n",
    "\n",
    "    # test metrics\n",
    "    yt, pt = probs_and_labels(test_ds, model)\n",
    "    pred = (pt >= th[\"t\"]).astype(int)\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"auc\": float(roc_auc_score(yt, pt)),\n",
    "        \"bal_acc\": float(balanced_accuracy_score(yt, pred)),\n",
    "        \"f1\": float(f1_score(yt, pred)),\n",
    "        \"precision\": float(precision_score(yt, pred)),\n",
    "        \"recall\": float(recall_score(yt, pred)),\n",
    "        \"thr\": th\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e48187cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m5761/5761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3270s\u001b[0m 566ms/step - acc: 0.7094 - auc: 0.7826 - loss: 0.5599 - val_acc: 0.7539 - val_auc: 0.8382 - val_loss: 0.5051\n",
      "Epoch 2/3\n",
      "\u001b[1m5761/5761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3197s\u001b[0m 555ms/step - acc: 0.7229 - auc: 0.7982 - loss: 0.5442 - val_acc: 0.7608 - val_auc: 0.8423 - val_loss: 0.4973\n",
      "Epoch 3/3\n",
      "\u001b[1m5761/5761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3211s\u001b[0m 557ms/step - acc: 0.7232 - auc: 0.7995 - loss: 0.5429 - val_acc: 0.7559 - val_auc: 0.8422 - val_loss: 0.4994\n",
      "Epoch 1/3\n",
      "\u001b[1m5761/5761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3821s\u001b[0m 662ms/step - acc: 0.7797 - auc: 0.8646 - loss: 0.4569 - val_acc: 0.8823 - val_auc: 0.9525 - val_loss: 0.2865\n",
      "Epoch 2/3\n",
      "\u001b[1m5761/5761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3740s\u001b[0m 649ms/step - acc: 0.8743 - auc: 0.9473 - loss: 0.2941 - val_acc: 0.9172 - val_auc: 0.9755 - val_loss: 0.2057\n",
      "Epoch 3/3\n",
      "\u001b[1m5761/5761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3767s\u001b[0m 654ms/step - acc: 0.9037 - auc: 0.9670 - loss: 0.2331 - val_acc: 0.9338 - val_auc: 0.9833 - val_loss: 0.1685\n",
      "\n",
      " AB->C {'auc': 0.4099789670483758, 'bal_acc': 0.5068357092778687, 'f1': 0.3614457831325301, 'precision': 0.2229299363057325, 'recall': 0.9545454545454546}\n",
      "threshold: 0.43999999999999995\n",
      "confusion matrix [[TN FP],[FN TP]]:\n",
      " [[ 23 366]\n",
      " [  5 105]]\n",
      "Epoch 1/3\n",
      "\u001b[1m2273/2273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1279s\u001b[0m 560ms/step - acc: 0.7757 - auc: 0.8587 - loss: 0.4707 - val_acc: 0.8243 - val_auc: 0.9117 - val_loss: 0.4005\n",
      "Epoch 2/3\n",
      "\u001b[1m2273/2273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1274s\u001b[0m 560ms/step - acc: 0.8066 - auc: 0.8870 - loss: 0.4234 - val_acc: 0.8284 - val_auc: 0.9244 - val_loss: 0.3840\n",
      "Epoch 3/3\n",
      "\u001b[1m2273/2273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1282s\u001b[0m 564ms/step - acc: 0.8098 - auc: 0.8901 - loss: 0.4176 - val_acc: 0.8467 - val_auc: 0.9243 - val_loss: 0.3627\n",
      "Epoch 1/3\n",
      "\u001b[1m2273/2273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1570s\u001b[0m 686ms/step - acc: 0.8249 - auc: 0.9053 - loss: 0.3890 - val_acc: 0.9021 - val_auc: 0.9657 - val_loss: 0.2496\n",
      "Epoch 2/3\n",
      "\u001b[1m2273/2273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1538s\u001b[0m 677ms/step - acc: 0.8882 - auc: 0.9564 - loss: 0.2694 - val_acc: 0.9313 - val_auc: 0.9814 - val_loss: 0.1841\n",
      "Epoch 3/3\n",
      "\u001b[1m2273/2273\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1522s\u001b[0m 670ms/step - acc: 0.9134 - auc: 0.9729 - loss: 0.2139 - val_acc: 0.9429 - val_auc: 0.9879 - val_loss: 0.1507\n",
      "\n",
      " AC->B {'auc': 0.5179217232017711, 'bal_acc': 0.5132683126820073, 'f1': 0.5412313271738192, 'precision': 0.50810635538262, 'recall': 0.5789765379641604}\n",
      "threshold: 0.3499999999999999\n",
      "confusion matrix [[TN FP],[FN TP]]:\n",
      " [[2458 3034]\n",
      " [2279 3134]]\n",
      "Epoch 1/3\n",
      "\u001b[1m3512/3512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2000s\u001b[0m 568ms/step - acc: 0.7692 - auc: 0.8514 - loss: 0.4771 - val_acc: 0.8074 - val_auc: 0.8899 - val_loss: 0.4234\n",
      "Epoch 2/3\n",
      "\u001b[1m3512/3512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1959s\u001b[0m 558ms/step - acc: 0.7842 - auc: 0.8665 - loss: 0.4549 - val_acc: 0.8115 - val_auc: 0.8940 - val_loss: 0.4184\n",
      "Epoch 3/3\n",
      "\u001b[1m3512/3512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1971s\u001b[0m 561ms/step - acc: 0.7866 - auc: 0.8688 - loss: 0.4513 - val_acc: 0.8134 - val_auc: 0.8963 - val_loss: 0.4142\n",
      "Epoch 1/3\n",
      "\u001b[1m3512/3512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2393s\u001b[0m 679ms/step - acc: 0.8261 - auc: 0.9101 - loss: 0.3784 - val_acc: 0.9056 - val_auc: 0.9675 - val_loss: 0.2345\n",
      "Epoch 2/3\n",
      "\u001b[1m3512/3512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2324s\u001b[0m 662ms/step - acc: 0.8980 - auc: 0.9636 - loss: 0.2442 - val_acc: 0.9296 - val_auc: 0.9810 - val_loss: 0.1781\n",
      "Epoch 3/3\n",
      "\u001b[1m3512/3512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2371s\u001b[0m 675ms/step - acc: 0.9159 - auc: 0.9745 - loss: 0.2040 - val_acc: 0.9394 - val_auc: 0.9859 - val_loss: 0.1529\n",
      "\n",
      " BC->A {'auc': 0.9723292243594156, 'bal_acc': 0.9270961282602148, 'f1': 0.9278915229885057, 'precision': 0.9484167049105094, 'recall': 0.9082359145644722}\n",
      "threshold: 0.41999999999999993\n",
      "confusion matrix [[TN FP],[FN TP]]:\n",
      " [[ 9837   562]\n",
      " [ 1044 10333]]\n",
      "auc mean±std = 0.6334099715365208 ± 0.24367000171272593\n",
      "bal_acc mean±std = 0.6490667167400302 ± 0.19661402094685215\n",
      "f1 mean±std = 0.6101895444316184 ± 0.2363353843527968\n",
      "precision mean±std = 0.559817665532954 ± 0.29842733068900634\n",
      "recall mean±std = 0.813919302358029 ± 0.1672019144210321\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_y_true(ds):\n",
    "    return np.concatenate([y.numpy().reshape(-1) for _, y in ds]).astype(int)\n",
    "\n",
    "def get_y_prob(model, ds):\n",
    "    return model.predict(ds, verbose=0).reshape(-1)\n",
    "\n",
    "# Dataset units\n",
    "A_train = (train_dir_A, train_labels_A)\n",
    "A_test  = (test_dir_A,  test_labels_A)\n",
    "B_train = (train_dir_B, train_labels_B)\n",
    "B_test  = (test_dir_B,  test_labels_B)\n",
    "C_train = (train_dir_C, train_labels_C)\n",
    "C_test  = (test_dir_C,  test_labels_C)\n",
    "\n",
    "folds = [\n",
    "    ([A_train, B_train], C_test, \"AB->C\"),\n",
    "    ([A_train, C_train], B_test, \"AC->B\"),\n",
    "    ([B_train, C_train], A_test, \"BC->A\"),\n",
    "]\n",
    "\n",
    "results = []\n",
    "for train_pairs, test_pair, name in folds:\n",
    "    train_ds, val_ds, test_ds = build_fold(train_pairs, test_pair)\n",
    "\n",
    "    r = run_fold(train_ds, val_ds, test_ds)   # <- r must include r[\"model\"] and r[\"thr\"][\"t\"] (or pick 0.5)\n",
    "    r[\"fold\"] = name\n",
    "\n",
    "    model = r[\"model\"]\n",
    "    thr = r[\"thr\"][\"t\"] if isinstance(r.get(\"thr\"), dict) and \"t\" in r[\"thr\"] else 0.5\n",
    "\n",
    "    y_true = get_y_true(test_ds)\n",
    "    y_prob = get_y_prob(model, test_ds)\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    r[\"cm\"] = cm\n",
    "\n",
    "    results.append(r)\n",
    "\n",
    "    print(\"\\n\", name, {k: r[k] for k in [\"auc\",\"bal_acc\",\"f1\",\"precision\",\"recall\"] if k in r})\n",
    "    print(\"threshold:\", thr)\n",
    "    print(\"confusion matrix [[TN FP],[FN TP]]:\\n\", cm)\n",
    "\n",
    "# average\n",
    "for k in [\"auc\",\"bal_acc\",\"f1\",\"precision\",\"recall\"]:\n",
    "    vals = [r[k] for r in results]\n",
    "    print(k, \"mean±std =\", float(np.mean(vals)), \"±\", float(np.std(vals)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a128209",
   "metadata": {},
   "source": [
    "Epoch 1/3\n",
    "5761/5761 ━━━━━━━━━━━━━━━━━━━━ 3270s 566ms/step - acc: 0.7094 - auc: 0.7826 - loss: 0.5599 - val_acc: 0.7539 - val_auc: 0.8382 - val_loss: 0.5051\n",
    "Epoch 2/3\n",
    "5761/5761 ━━━━━━━━━━━━━━━━━━━━ 3197s 555ms/step - acc: 0.7229 - auc: 0.7982 - loss: 0.5442 - val_acc: 0.7608 - val_auc: 0.8423 - val_loss: 0.4973\n",
    "Epoch 3/3\n",
    "5761/5761 ━━━━━━━━━━━━━━━━━━━━ 3211s 557ms/step - acc: 0.7232 - auc: 0.7995 - loss: 0.5429 - val_acc: 0.7559 - val_auc: 0.8422 - val_loss: 0.4994\n",
    "Epoch 1/3\n",
    "5761/5761 ━━━━━━━━━━━━━━━━━━━━ 3821s 662ms/step - acc: 0.7797 - auc: 0.8646 - loss: 0.4569 - val_acc: 0.8823 - val_auc: 0.9525 - val_loss: 0.2865\n",
    "Epoch 2/3\n",
    "5761/5761 ━━━━━━━━━━━━━━━━━━━━ 3740s 649ms/step - acc: 0.8743 - auc: 0.9473 - loss: 0.2941 - val_acc: 0.9172 - val_auc: 0.9755 - val_loss: 0.2057\n",
    "Epoch 3/3\n",
    "5761/5761 ━━━━━━━━━━━━━━━━━━━━ 3767s 654ms/step - acc: 0.9037 - auc: 0.9670 - loss: 0.2331 - val_acc: 0.9338 - val_auc: 0.9833 - val_loss: 0.1685\n",
    "\n",
    " AB->C {'auc': 0.4099789670483758, 'bal_acc': 0.5068357092778687, 'f1': 0.3614457831325301, 'precision': 0.2229299363057325, 'recall': 0.9545454545454546}\n",
    "threshold: 0.43999999999999995\n",
    "confusion matrix [[TN FP],[FN TP]]:\n",
    " [[ 23 366]\n",
    " [  5 105]]\n",
    "Epoch 1/3\n",
    "2273/2273 ━━━━━━━━━━━━━━━━━━━━ 1279s 560ms/step - acc: 0.7757 - auc: 0.8587 - loss: 0.4707 - val_acc: 0.8243 - val_auc: 0.9117 - val_loss: 0.4005\n",
    "Epoch 2/3\n",
    "2273/2273 ━━━━━━━━━━━━━━━━━━━━ 1274s 560ms/step - acc: 0.8066 - auc: 0.8870 - loss: 0.4234 - val_acc: 0.8284 - val_auc: 0.9244 - val_loss: 0.3840\n",
    "Epoch 3/3\n",
    "2273/2273 ━━━━━━━━━━━━━━━━━━━━ 1282s 564ms/step - acc: 0.8098 - auc: 0.8901 - loss: 0.4176 - val_acc: 0.8467 - val_auc: 0.9243 - val_loss: 0.3627\n",
    "Epoch 1/3\n",
    "2273/2273 ━━━━━━━━━━━━━━━━━━━━ 1570s 686ms/step - acc: 0.8249 - auc: 0.9053 - loss: 0.3890 - val_acc: 0.9021 - val_auc: 0.9657 - val_loss: 0.2496\n",
    "Epoch 2/3\n",
    "2273/2273 ━━━━━━━━━━━━━━━━━━━━ 1538s 677ms/step - acc: 0.8882 - auc: 0.9564 - loss: 0.2694 - val_acc: 0.9313 - val_auc: 0.9814 - val_loss: 0.1841\n",
    "Epoch 3/3\n",
    "2273/2273 ━━━━━━━━━━━━━━━━━━━━ 1522s 670ms/step - acc: 0.9134 - auc: 0.9729 - loss: 0.2139 - val_acc: 0.9429 - val_auc: 0.9879 - val_loss: 0.1507\n",
    "\n",
    " AC->B {'auc': 0.5179217232017711, 'bal_acc': 0.5132683126820073, 'f1': 0.5412313271738192, 'precision': 0.50810635538262, 'recall': 0.5789765379641604}\n",
    "threshold: 0.3499999999999999\n",
    "confusion matrix [[TN FP],[FN TP]]:\n",
    " [[2458 3034]\n",
    " [2279 3134]]\n",
    "Epoch 1/3\n",
    "3512/3512 ━━━━━━━━━━━━━━━━━━━━ 2000s 568ms/step - acc: 0.7692 - auc: 0.8514 - loss: 0.4771 - val_acc: 0.8074 - val_auc: 0.8899 - val_loss: 0.4234\n",
    "Epoch 2/3\n",
    "3512/3512 ━━━━━━━━━━━━━━━━━━━━ 1959s 558ms/step - acc: 0.7842 - auc: 0.8665 - loss: 0.4549 - val_acc: 0.8115 - val_auc: 0.8940 - val_loss: 0.4184\n",
    "Epoch 3/3\n",
    "3512/3512 ━━━━━━━━━━━━━━━━━━━━ 1971s 561ms/step - acc: 0.7866 - auc: 0.8688 - loss: 0.4513 - val_acc: 0.8134 - val_auc: 0.8963 - val_loss: 0.4142\n",
    "Epoch 1/3\n",
    "3512/3512 ━━━━━━━━━━━━━━━━━━━━ 2393s 679ms/step - acc: 0.8261 - auc: 0.9101 - loss: 0.3784 - val_acc: 0.9056 - val_auc: 0.9675 - val_loss: 0.2345\n",
    "Epoch 2/3\n",
    "3512/3512 ━━━━━━━━━━━━━━━━━━━━ 2324s 662ms/step - acc: 0.8980 - auc: 0.9636 - loss: 0.2442 - val_acc: 0.9296 - val_auc: 0.9810 - val_loss: 0.1781\n",
    "Epoch 3/3\n",
    "3512/3512 ━━━━━━━━━━━━━━━━━━━━ 2371s 675ms/step - acc: 0.9159 - auc: 0.9745 - loss: 0.2040 - val_acc: 0.9394 - val_auc: 0.9859 - val_loss: 0.1529\n",
    "\n",
    " BC->A {'auc': 0.9723292243594156, 'bal_acc': 0.9270961282602148, 'f1': 0.9278915229885057, 'precision': 0.9484167049105094, 'recall': 0.9082359145644722}\n",
    "threshold: 0.41999999999999993\n",
    "confusion matrix [[TN FP],[FN TP]]:\n",
    " [[ 9837   562]\n",
    " [ 1044 10333]]\n",
    "auc mean±std = 0.6334099715365208 ± 0.24367000171272593\n",
    "bal_acc mean±std = 0.6490667167400302 ± 0.19661402094685215\n",
    "f1 mean±std = 0.6101895444316184 ± 0.2363353843527968\n",
    "precision mean±std = 0.559817665532954 ± 0.29842733068900634\n",
    "recall mean±std = 0.813919302358029 ± 0.1672019144210321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a79280c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m5773/5773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3260s\u001b[0m 564ms/step - acc: 0.7071 - auc: 0.7808 - loss: 0.5617 - val_acc: 0.7588 - val_auc: 0.8400 - val_loss: 0.5007\n",
      "Epoch 2/3\n",
      "\u001b[1m5773/5773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3199s\u001b[0m 554ms/step - acc: 0.7229 - auc: 0.7968 - loss: 0.5459 - val_acc: 0.7607 - val_auc: 0.8426 - val_loss: 0.4959\n",
      "Epoch 3/3\n",
      "\u001b[1m5773/5773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3099s\u001b[0m 537ms/step - acc: 0.7246 - auc: 0.7990 - loss: 0.5438 - val_acc: 0.7646 - val_auc: 0.8456 - val_loss: 0.4936\n",
      "Epoch 1/3\n",
      "\u001b[1m5773/5773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3723s\u001b[0m 643ms/step - acc: 0.7795 - auc: 0.8629 - loss: 0.4596 - val_acc: 0.8801 - val_auc: 0.9513 - val_loss: 0.2896\n",
      "Epoch 2/3\n",
      "\u001b[1m5773/5773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3698s\u001b[0m 641ms/step - acc: 0.8749 - auc: 0.9476 - loss: 0.2935 - val_acc: 0.9166 - val_auc: 0.9745 - val_loss: 0.2098\n",
      "Epoch 3/3\n",
      "\u001b[1m5773/5773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3699s\u001b[0m 641ms/step - acc: 0.9030 - auc: 0.9665 - loss: 0.2349 - val_acc: 0.9332 - val_auc: 0.9826 - val_loss: 0.1707\n",
      "FINAL threshold: {'t': 0.43999999999999995, 'f1': 0.9367072789753202, 'precision': 0.9324156231860021, 'recall': 0.9410386240950747, 'bal_acc': 0.9339410615201822}\n",
      "Saved: C:\\Users\\blend\\Inzynierka\\Models\\deepfake_detector.keras C:\\Users\\blend\\Inzynierka\\Models\\threshold.json\n"
     ]
    }
   ],
   "source": [
    "# --- FINAL TRAIN POOL: A+B+C (train splits only) ---\n",
    "ALL_train_paths  = train_dir_A + train_dir_B + train_dir_C\n",
    "ALL_train_labels = train_labels_A + train_labels_B + train_labels_C\n",
    "\n",
    "# internal split for early stopping + threshold calibration\n",
    "trp, try_, vap, vay = split_train_val(ALL_train_paths, ALL_train_labels)\n",
    "\n",
    "final_train_ds = make_ds(trp, try_, training=True)\n",
    "final_val_ds   = make_ds(vap, vay, training=False)\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
    "\n",
    "base = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(256,256,3))\n",
    "base.trainable = False\n",
    "\n",
    "final_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input((256,256,3)),\n",
    "    tf.keras.layers.Lambda(preprocess_input),\n",
    "    base,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "def compile_final(lr):\n",
    "    final_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[tf.keras.metrics.AUC(name=\"auc\"),\n",
    "                 tf.keras.metrics.BinaryAccuracy(name=\"acc\", threshold=0.5)]\n",
    "    )\n",
    "\n",
    "# stage 1\n",
    "compile_final(1e-3)\n",
    "final_model.fit(\n",
    "    final_train_ds,\n",
    "    validation_data=final_val_ds,\n",
    "    epochs=3,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=1, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "# stage 2 fine-tune\n",
    "base.trainable = True\n",
    "for layer in base.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "compile_final(1e-5)\n",
    "final_model.fit(\n",
    "    final_train_ds,\n",
    "    validation_data=final_val_ds,\n",
    "    epochs=3,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=1, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "\n",
    "# threshold calibrated on internal validation set\n",
    "final_thr = best_threshold_on_val(final_model, final_val_ds)\n",
    "print(\"FINAL threshold:\", final_thr)\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "Path(\"Models\").mkdir(exist_ok=True)\n",
    "\n",
    "# save model\n",
    "final_model.save(\"Models/deepfake_detector.keras\")\n",
    "\n",
    "# save threshold + val metrics (so your app can use the same threshold)\n",
    "with open(\"Models/threshold.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_thr, f, indent=2)\n",
    "\n",
    "print(\"Saved:\",\n",
    "      Path(\"Models/deepfake_detector.keras\").resolve(),\n",
    "      Path(\"Models/threshold.json\").resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89b594c",
   "metadata": {},
   "source": [
    "Epoch 1/3\n",
    "5773/5773 ━━━━━━━━━━━━━━━━━━━━ 3260s 564ms/step - acc: 0.7071 - auc: 0.7808 - loss: 0.5617 - val_acc: 0.7588 - val_auc: 0.8400 - val_loss: 0.5007\n",
    "Epoch 2/3\n",
    "5773/5773 ━━━━━━━━━━━━━━━━━━━━ 3199s 554ms/step - acc: 0.7229 - auc: 0.7968 - loss: 0.5459 - val_acc: 0.7607 - val_auc: 0.8426 - val_loss: 0.4959\n",
    "Epoch 3/3\n",
    "5773/5773 ━━━━━━━━━━━━━━━━━━━━ 3099s 537ms/step - acc: 0.7246 - auc: 0.7990 - loss: 0.5438 - val_acc: 0.7646 - val_auc: 0.8456 - val_loss: 0.4936\n",
    "Epoch 1/3\n",
    "5773/5773 ━━━━━━━━━━━━━━━━━━━━ 3723s 643ms/step - acc: 0.7795 - auc: 0.8629 - loss: 0.4596 - val_acc: 0.8801 - val_auc: 0.9513 - val_loss: 0.2896\n",
    "Epoch 2/3\n",
    "5773/5773 ━━━━━━━━━━━━━━━━━━━━ 3698s 641ms/step - acc: 0.8749 - auc: 0.9476 - loss: 0.2935 - val_acc: 0.9166 - val_auc: 0.9745 - val_loss: 0.2098\n",
    "Epoch 3/3\n",
    "5773/5773 ━━━━━━━━━━━━━━━━━━━━ 3699s 641ms/step - acc: 0.9030 - auc: 0.9665 - loss: 0.2349 - val_acc: 0.9332 - val_auc: 0.9826 - val_loss: 0.1707\n",
    "FINAL threshold: {'t': 0.43999999999999995, 'f1': 0.9367072789753202, 'precision': 0.9324156231860021, 'recall': 0.9410386240950747, 'bal_acc': 0.9339410615201822}\n",
    "Saved: C:\\Users\\blend\\Inzynierka\\Models\\deepfake_detector.keras C:\\Users\\blend\\Inzynierka\\Models\\threshold.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba7445ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weights:\n",
      "C:\\Users\\blend\\Inzynierka\\Models\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path(\"Modele\").mkdir(exist_ok=True)\n",
    "\n",
    "# TensorFlow checkpoint format (recommended; avoids .h5 / h5py issues)\n",
    "final_model.save_weights(\"Modele/deepfake_model_weights.weights.h5\")\n",
    "with open(\"Modele/threshold.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_thr, f, indent=2)\n",
    "\n",
    "print(\"Saved weights:\")\n",
    "print(Path(\"Models\").resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "080e17c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: C:\\Users\\blend\\anaconda3\\python.exe\n",
      "tf: 2.20.0\n",
      "keras: 3.13.1\n"
     ]
    }
   ],
   "source": [
    "import sys, tensorflow as tf, keras\n",
    "print(\"python:\", sys.executable)\n",
    "print(\"tf:\", tf.__version__)\n",
    "print(\"keras:\", keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1969690f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,377</span> (364.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m93,377\u001b[0m (364.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,377</span> (364.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m93,377\u001b[0m (364.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m853s\u001b[0m 377ms/step - acc: 0.5680 - auc: 0.5908 - loss: 0.6810 - precision: 0.5655 - recall: 0.8652 - val_acc: 0.5925 - val_auc: 0.6338 - val_loss: 0.6744 - val_precision: 0.6447 - val_recall: 0.5411\n",
      "Epoch 2/3\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m863s\u001b[0m 382ms/step - acc: 0.6122 - auc: 0.6464 - loss: 0.6612 - precision: 0.6290 - recall: 0.6880 - val_acc: 0.6326 - val_auc: 0.6925 - val_loss: 0.6503 - val_precision: 0.6102 - val_recall: 0.8789\n",
      "Epoch 3/3\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m864s\u001b[0m 382ms/step - acc: 0.6526 - auc: 0.7003 - loss: 0.6313 - precision: 0.6686 - recall: 0.7082 - val_acc: 0.6061 - val_auc: 0.7240 - val_loss: 0.6571 - val_precision: 0.5808 - val_recall: 0.9643\n",
      "\n",
      "TEST (Keras metrics):\n",
      "{'loss': 0.7267244458198547, 'compile_metrics': 0.4897134602069855}\n",
      "\n",
      "Confusion matrix:\n",
      " [[3630 6769]\n",
      " [4343 7034]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fake     0.4553    0.3491    0.3952     10399\n",
      "        real     0.5096    0.6183    0.5587     11377\n",
      "\n",
      "    accuracy                         0.4897     21776\n",
      "   macro avg     0.4824    0.4837    0.4769     21776\n",
      "weighted avg     0.4837    0.4897    0.4806     21776\n",
      "\n",
      "ROC-AUC: 0.4987999138496348\n"
     ]
    }
   ],
   "source": [
    "# ===== CNN (baseline) =====\n",
    "TH = 0.5  # próg klasyfikacji\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(256, 256, 3)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name=\"acc\", threshold=TH),\n",
    "        tf.keras.metrics.Precision(name=\"precision\", thresholds=TH),\n",
    "        tf.keras.metrics.Recall(name=\"recall\", thresholds=TH),\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ===== Trening (na start krótko) =====\n",
    "history = model.fit(\n",
    "    model_train,\n",
    "    validation_data=model_val,\n",
    "    epochs=3,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=1, restore_best_weights=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ===== Ewaluacja na teście =====\n",
    "print(\"\\nTEST (Keras metrics):\")\n",
    "print(dict(zip(model.metrics_names, model.evaluate(model_test, return_dict=True, verbose=0))))\n",
    "\n",
    "# ===== Dodatkowe metryki: confusion matrix, report, ROC-AUC =====\n",
    "y_true = np.concatenate([y.numpy().reshape(-1) for _, y in model_test], axis=0)\n",
    "y_prob = model.predict(model_test, verbose=0).reshape(-1)\n",
    "y_pred = (y_prob >= TH).astype(int)\n",
    "\n",
    "try:\n",
    "    from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"\\nConfusion matrix:\\n\", cm)\n",
    "\n",
    "    # class_names: np. ['fake','real'] => 0->fake, 1->real\n",
    "    print(\"\\nClassification report:\\n\",\n",
    "          classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "    print(\"ROC-AUC:\", roc_auc_score(y_true, y_prob))\n",
    "except Exception as e:\n",
    "    print(\"Brak sklearn lub błąd w metrykach dodatkowych:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c18d66a",
   "metadata": {},
   "source": [
    "Model: \"sequential\"\n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
    "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
    "│ conv2d (Conv2D)                 │ (None, 256, 256, 32)   │           896 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ max_pooling2d (MaxPooling2D)    │ (None, 128, 128, 32)   │             0 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ conv2d_1 (Conv2D)               │ (None, 128, 128, 64)   │        18,496 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ max_pooling2d_1 (MaxPooling2D)  │ (None, 64, 64, 64)     │             0 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ conv2d_2 (Conv2D)               │ (None, 64, 64, 128)    │        73,856 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ max_pooling2d_2 (MaxPooling2D)  │ (None, 32, 32, 128)    │             0 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ global_average_pooling2d        │ (None, 128)            │             0 │\n",
    "│ (GlobalAveragePooling2D)        │                        │               │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dropout (Dropout)               │ (None, 128)            │             0 │\n",
    "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
    "│ dense (Dense)                   │ (None, 1)              │           129 │\n",
    "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
    " Total params: 93,377 (364.75 KB)\n",
    " Trainable params: 93,377 (364.75 KB)\n",
    " Non-trainable params: 0 (0.00 B)\n",
    "Epoch 1/3\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 853s 377ms/step - acc: 0.5680 - auc: 0.5908 - loss: 0.6810 - precision: 0.5655 - recall: 0.8652 - val_acc: 0.5925 - val_auc: 0.6338 - val_loss: 0.6744 - val_precision: 0.6447 - val_recall: 0.5411\n",
    "Epoch 2/3\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 863s 382ms/step - acc: 0.6122 - auc: 0.6464 - loss: 0.6612 - precision: 0.6290 - recall: 0.6880 - val_acc: 0.6326 - val_auc: 0.6925 - val_loss: 0.6503 - val_precision: 0.6102 - val_recall: 0.8789\n",
    "Epoch 3/3\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 864s 382ms/step - acc: 0.6526 - auc: 0.7003 - loss: 0.6313 - precision: 0.6686 - recall: 0.7082 - val_acc: 0.6061 - val_auc: 0.7240 - val_loss: 0.6571 - val_precision: 0.5808 - val_recall: 0.9643\n",
    "\n",
    "TEST (Keras metrics):\n",
    "{'loss': 0.7267244458198547, 'compile_metrics': 0.4897134602069855}\n",
    "\n",
    "Confusion matrix:\n",
    " [[3630 6769]\n",
    " [4343 7034]]\n",
    "\n",
    "Classification report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "        fake     0.4553    0.3491    0.3952     10399\n",
    "        real     0.5096    0.6183    0.5587     11377\n",
    "\n",
    "    accuracy                         0.4897     21776\n",
    "   macro avg     0.4824    0.4837    0.4769     21776\n",
    "weighted avg     0.4837    0.4897    0.4806     21776\n",
    "\n",
    "ROC-AUC: 0.4987999138496348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "149ade73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1253s\u001b[0m 552ms/step - acc: 0.7688 - auc: 0.8620 - loss: 0.4654 - precision: 0.7410 - recall: 0.8793 - val_acc: 0.8344 - val_auc: 0.9120 - val_loss: 0.3980 - val_precision: 0.8422 - val_recall: 0.8522\n",
      "Epoch 2/6\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1193s\u001b[0m 528ms/step - acc: 0.8017 - auc: 0.8900 - loss: 0.4174 - precision: 0.7816 - recall: 0.8784 - val_acc: 0.8428 - val_auc: 0.9222 - val_loss: 0.3664 - val_precision: 0.8284 - val_recall: 0.8932\n",
      "Epoch 3/6\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1252s\u001b[0m 554ms/step - acc: 0.8072 - auc: 0.8936 - loss: 0.4104 - precision: 0.7877 - recall: 0.8806 - val_acc: 0.8525 - val_auc: 0.9280 - val_loss: 0.3586 - val_precision: 0.8524 - val_recall: 0.8783\n",
      "Epoch 4/6\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1247s\u001b[0m 551ms/step - acc: 0.8074 - auc: 0.8950 - loss: 0.4075 - precision: 0.7899 - recall: 0.8766 - val_acc: 0.8543 - val_auc: 0.9300 - val_loss: 0.3519 - val_precision: 0.8502 - val_recall: 0.8855\n",
      "Epoch 5/6\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1231s\u001b[0m 545ms/step - acc: 0.8095 - auc: 0.8955 - loss: 0.4067 - precision: 0.7917 - recall: 0.8785 - val_acc: 0.8527 - val_auc: 0.9297 - val_loss: 0.3486 - val_precision: 0.8416 - val_recall: 0.8951\n",
      "Epoch 1/6\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1502s\u001b[0m 660ms/step - acc: 0.8188 - auc: 0.9052 - loss: 0.3917 - precision: 0.7989 - recall: 0.8882 - val_acc: 0.9061 - val_auc: 0.9682 - val_loss: 0.2370 - val_precision: 0.9051 - val_recall: 0.9225\n",
      "Epoch 2/6\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1474s\u001b[0m 652ms/step - acc: 0.8838 - auc: 0.9559 - loss: 0.2683 - precision: 0.8709 - recall: 0.9215 - val_acc: 0.9344 - val_auc: 0.9831 - val_loss: 0.1764 - val_precision: 0.9396 - val_recall: 0.9385\n",
      "Epoch 3/6\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1493s\u001b[0m 661ms/step - acc: 0.9109 - auc: 0.9720 - loss: 0.2149 - precision: 0.9005 - recall: 0.9388 - val_acc: 0.9520 - val_auc: 0.9899 - val_loss: 0.1383 - val_precision: 0.9562 - val_recall: 0.9546\n",
      "Epoch 4/6\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1469s\u001b[0m 650ms/step - acc: 0.9295 - auc: 0.9815 - loss: 0.1755 - precision: 0.9207 - recall: 0.9514 - val_acc: 0.9606 - val_auc: 0.9928 - val_loss: 0.1148 - val_precision: 0.9629 - val_recall: 0.9640\n",
      "Epoch 5/6\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1425s\u001b[0m 630ms/step - acc: 0.9394 - auc: 0.9863 - loss: 0.1505 - precision: 0.9310 - recall: 0.9589 - val_acc: 0.9656 - val_auc: 0.9945 - val_loss: 0.1001 - val_precision: 0.9694 - val_recall: 0.9666\n",
      "Epoch 6/6\n",
      "\u001b[1m2261/2261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1469s\u001b[0m 650ms/step - acc: 0.9468 - auc: 0.9893 - loss: 0.1327 - precision: 0.9392 - recall: 0.9638 - val_acc: 0.9697 - val_auc: 0.9958 - val_loss: 0.0896 - val_precision: 0.9759 - val_recall: 0.9677\n",
      "Test (Keras): {'acc': 0.5729243159294128, 'auc': 0.6681026220321655, 'loss': 1.969002604484558, 'precision': 0.9001926779747009, 'recall': 0.20532654225826263}\n",
      "ROC-AUC: 0.6697694612203459\n",
      "Confusion matrix:\n",
      " [[10140   259]\n",
      " [ 9041  2336]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake     0.5286    0.9751    0.6856     10399\n",
      "        real     0.9002    0.2053    0.3344     11377\n",
      "\n",
      "    accuracy                         0.5729     21776\n",
      "   macro avg     0.7144    0.5902    0.5100     21776\n",
      "weighted avg     0.7228    0.5729    0.5021     21776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "TH = 0.45\n",
    "\n",
    "base = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(256,256,3))\n",
    "base.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input((256,256,3)),\n",
    "    tf.keras.layers.Lambda(preprocess_input),\n",
    "    base,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "def compile_model(lr):\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\n",
    "            tf.keras.metrics.BinaryAccuracy(name=\"acc\", threshold=TH),\n",
    "            tf.keras.metrics.Precision(name=\"precision\", thresholds=TH),\n",
    "            tf.keras.metrics.Recall(name=\"recall\", thresholds=TH),\n",
    "            tf.keras.metrics.AUC(name=\"auc\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# ---- Stage 1: train head (feature extractor) ----\n",
    "compile_model(1e-3)\n",
    "history_1 = model.fit(\n",
    "    model_train,\n",
    "    validation_data=model_val,\n",
    "    epochs=3,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=1, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "# ---- Stage 2: fine-tuning ----\n",
    "base.trainable = True\n",
    "for layer in base.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "compile_model(1e-5)\n",
    "history_2 = model.fit(\n",
    "    model_train,\n",
    "    validation_data=model_val,\n",
    "    epochs=3,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=1, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "# ---- Final test evaluation ----\n",
    "print(\"Test (Keras):\", model.evaluate(model_test, return_dict=True, verbose=0))\n",
    "\n",
    "y_true = np.concatenate([y.numpy().reshape(-1) for _, y in model_test], axis=0)\n",
    "y_prob = model.predict(model_test, verbose=0).reshape(-1)\n",
    "y_pred = (y_prob >= TH).astype(int)\n",
    "\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_true, y_prob))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794edba6",
   "metadata": {},
   "source": [
    "Epoch 1/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1253s 552ms/step - acc: 0.7688 - auc: 0.8620 - loss: 0.4654 - precision: 0.7410 - recall: 0.8793 - val_acc: 0.8344 - val_auc: 0.9120 - val_loss: 0.3980 - val_precision: 0.8422 - val_recall: 0.8522\n",
    "Epoch 2/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1193s 528ms/step - acc: 0.8017 - auc: 0.8900 - loss: 0.4174 - precision: 0.7816 - recall: 0.8784 - val_acc: 0.8428 - val_auc: 0.9222 - val_loss: 0.3664 - val_precision: 0.8284 - val_recall: 0.8932\n",
    "Epoch 3/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1252s 554ms/step - acc: 0.8072 - auc: 0.8936 - loss: 0.4104 - precision: 0.7877 - recall: 0.8806 - val_acc: 0.8525 - val_auc: 0.9280 - val_loss: 0.3586 - val_precision: 0.8524 - val_recall: 0.8783\n",
    "Epoch 4/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1247s 551ms/step - acc: 0.8074 - auc: 0.8950 - loss: 0.4075 - precision: 0.7899 - recall: 0.8766 - val_acc: 0.8543 - val_auc: 0.9300 - val_loss: 0.3519 - val_precision: 0.8502 - val_recall: 0.8855\n",
    "Epoch 5/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1231s 545ms/step - acc: 0.8095 - auc: 0.8955 - loss: 0.4067 - precision: 0.7917 - recall: 0.8785 - val_acc: 0.8527 - val_auc: 0.9297 - val_loss: 0.3486 - val_precision: 0.8416 - val_recall: 0.8951\n",
    "Epoch 1/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1502s 660ms/step - acc: 0.8188 - auc: 0.9052 - loss: 0.3917 - precision: 0.7989 - recall: 0.8882 - val_acc: 0.9061 - val_auc: 0.9682 - val_loss: 0.2370 - val_precision: 0.9051 - val_recall: 0.9225\n",
    "Epoch 2/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1474s 652ms/step - acc: 0.8838 - auc: 0.9559 - loss: 0.2683 - precision: 0.8709 - recall: 0.9215 - val_acc: 0.9344 - val_auc: 0.9831 - val_loss: 0.1764 - val_precision: 0.9396 - val_recall: 0.9385\n",
    "Epoch 3/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1493s 661ms/step - acc: 0.9109 - auc: 0.9720 - loss: 0.2149 - precision: 0.9005 - recall: 0.9388 - val_acc: 0.9520 - val_auc: 0.9899 - val_loss: 0.1383 - val_precision: 0.9562 - val_recall: 0.9546\n",
    "Epoch 4/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1469s 650ms/step - acc: 0.9295 - auc: 0.9815 - loss: 0.1755 - precision: 0.9207 - recall: 0.9514 - val_acc: 0.9606 - val_auc: 0.9928 - val_loss: 0.1148 - val_precision: 0.9629 - val_recall: 0.9640\n",
    "Epoch 5/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1425s 630ms/step - acc: 0.9394 - auc: 0.9863 - loss: 0.1505 - precision: 0.9310 - recall: 0.9589 - val_acc: 0.9656 - val_auc: 0.9945 - val_loss: 0.1001 - val_precision: 0.9694 - val_recall: 0.9666\n",
    "Epoch 6/6\n",
    "2261/2261 ━━━━━━━━━━━━━━━━━━━━ 1469s 650ms/step - acc: 0.9468 - auc: 0.9893 - loss: 0.1327 - precision: 0.9392 - recall: 0.9638 - val_acc: 0.9697 - val_auc: 0.9958 - val_loss: 0.0896 - val_precision: 0.9759 - val_recall: 0.9677\n",
    "Test (Keras): {'acc': 0.5729243159294128, 'auc': 0.6681026220321655, 'loss': 1.969002604484558, 'precision': 0.9001926779747009, 'recall': 0.20532654225826263}\n",
    "ROC-AUC: 0.6697694612203459\n",
    "Confusion matrix:\n",
    " [[10140   259]\n",
    " [ 9041  2336]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        fake     0.5286    0.9751    0.6856     10399\n",
    "        real     0.9002    0.2053    0.3344     11377\n",
    "\n",
    "    accuracy                         0.5729     21776\n",
    "   macro avg     0.7144    0.5902    0.5100     21776\n",
    "weighted avg     0.7228    0.5729    0.5021     21776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06630473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453b7f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3dd125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68302f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99857ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
